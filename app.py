"""
ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„ ë©”ì¸ Streamlit ì•±
"""
import os
import warnings
import traceback
from datetime import datetime, timedelta

import streamlit as st
import pandas as pd
import numpy as np
from dotenv import load_dotenv

from config.settings import app_config
from utils.data_reader import get_seoul_air_quality
from utils.data_processor import DataProcessor
from utils.visualizer import TimeSeriesVisualizer
from utils.llm_connector import LLMConnector
from prompts.time_series_analysis_prompt import TIME_SERIES_ANALYSIS_PROMPT

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')


OLLAMA_SERVER = os.getenv("OLLAMA_SERVER")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL")


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=app_config.APP_TITLE,
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ê°ì²´ ì´ˆê¸°í™”
data_processor = DataProcessor()
visualizer = TimeSeriesVisualizer()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'data_source' not in st.session_state:
        st.session_state.data_source = "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°"
    if 'selected_station' not in st.session_state:
        st.session_state.selected_station = None
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    if 'series' not in st.session_state:
        st.session_state.series = None
    if 'train' not in st.session_state:
        st.session_state.train = None
    if 'test' not in st.session_state:
        st.session_state.test = None
    if 'period' not in st.session_state:
        st.session_state.period = 24
    if 'decomposition' not in st.session_state:
        st.session_state.decomposition = None
    if 'stationarity_result' not in st.session_state:
        st.session_state.stationarity_result = None
    if 'acf_values' not in st.session_state:
        st.session_state.acf_values = None
    if 'pacf_values' not in st.session_state:
        st.session_state.pacf_values = None
    if 'forecasts' not in st.session_state:
        st.session_state.forecasts = {}
    if 'metrics' not in st.session_state:
        st.session_state.metrics = {}
    if 'models_trained' not in st.session_state:
        st.session_state.models_trained = False
    if 'selected_models' not in st.session_state:
        st.session_state.selected_models = []
    if 'test_size' not in st.session_state:
        st.session_state.test_size = app_config.DEFAULT_TEST_SIZE
    if 'best_model' not in st.session_state:
        st.session_state.best_model = None

# ëª¨ë¸ íŒ©í† ë¦¬ ë™ì  ë¡œë“œ
@st.cache_resource
def get_model_factory():
    """
    ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    í•„ìš”í•  ë•Œë§Œ importí•˜ì—¬ ì‹œì‘ ì‹œ pmdarima ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        from models.model_factory import ModelFactory
        return ModelFactory()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”: pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return None

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data
def load_data(file_path=None, start_date=None, end_date=None):
    """
    CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        if file_path and os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            return df
        else:
            st.info("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            
            if not start_date or not end_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ í•œ ë‹¬
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            
            df = get_seoul_air_quality(app_config.SEOUL_API_KEY, start_date, end_date)
            
            if df is not None and not df.empty:
                # íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(app_config.DATA_DIR, exist_ok=True)
                df.to_csv(app_config.DEFAULT_DATA_FILE, index=False, encoding='utf-8-sig')
                st.success(f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {app_config.DEFAULT_DATA_FILE}")
            
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì•± í—¤ë” í•¨ìˆ˜
def render_header():
    """
    ì•± í—¤ë” ë Œë”ë§
    """
    st.title("Air Quality Time Series Analysis")
    st.markdown("Seoul City IoT Data Time Series Analysis App")
    
    # í™•ì¥ ê°€ëŠ¥í•œ ì•± ì†Œê°œ
    with st.expander("ğŸ“Œ App Introduction and Usage"):
        st.markdown("""
        ### ğŸ“Œ ì•± ì†Œê°œ
        ì´ ì•±ì€ ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

        ### ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥
        1. **ë°ì´í„° íƒìƒ‰**: ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™” ì œê³µ
        2. **ì‹œê³„ì—´ ë¶„í•´**: ì¶”ì„¸(Trend), ê³„ì ˆì„±(Seasonality), ë¶ˆê·œì¹™ì„±(Irregularity) ë¶„ì„
        3. **ëª¨ë¸ ë¹„êµ**: ARIMA/SARIMA, ì§€ìˆ˜í‰í™œë²•, Prophet, LSTM ë“± ë‹¤ì–‘í•œ ì˜ˆì¸¡ ëª¨ë¸ ì§€ì›
        4. **ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€**: RMSE, MAE, RÂ² ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê¸°ë°˜ í‰ê°€

        ### ğŸ› ï¸ ì‚¬ìš© ë°©ë²•
        1. ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” API ìˆ˜ì§‘ ì˜µì…˜ ì„ íƒ
        2. ë¶„ì„í•  ì¸¡ì •ì†Œì™€ ë³€ìˆ˜(PM10, PM25 ë“±) ì„ íƒ
        3. ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜ ì„¤ì • í›„ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        4. ê²°ê³¼ íƒ­ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
        """)

# ë°ì´í„° ì†ŒìŠ¤ ë³€ê²½ ì½œë°±
def on_data_source_change():
    st.session_state.df = None
    st.session_state.series = None
    st.session_state.train = None
    st.session_state.test = None
    st.session_state.models_trained = False

# ì¸¡ì •ì†Œ/íƒ€ê²Ÿ ë³€ê²½ ì½œë°±
def update_series():
    if st.session_state.df is not None:
        # ì„ íƒëœ ì¸¡ì •ì†Œì™€ íƒ€ê²Ÿ ë³€ìˆ˜ì— ë”°ë¼ ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬
        st.session_state.series = data_processor.preprocess_data(
            st.session_state.df, 
            st.session_state.selected_target, 
            st.session_state.selected_station
        )
        # ëª¨ë¸ í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.train = None
        st.session_state.test = None
        st.session_state.models_trained = False

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_models():
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    st.session_state.train, st.session_state.test = data_processor.train_test_split(
        st.session_state.series, 
        st.session_state.test_size
    )
    
    # ëª¨ë¸ íŒ©í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    model_factory = get_model_factory()
    
    if model_factory is None:
        st.error("ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.error("ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
    forecasts = {}
    metrics = {}
    
    # ëª¨ë¸ ê°œìˆ˜
    total_models = len(st.session_state.selected_models)
    completed_models = 0
    
    # ê° ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    for model_type in st.session_state.selected_models:
        status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            model = model_factory.get_model(model_type)
            
            # ëª¨ë¸ë³„ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
            if model_type == 'arima':
                # ARIMA ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal=True,
                    m=st.session_state.period
                )
            elif model_type == 'exp_smoothing':
                # ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal_periods=st.session_state.period
                )
            elif model_type == 'prophet':
                # Prophet ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    daily_seasonality=True,
                    weekly_seasonality=True
                )
            elif model_type == 'lstm':
                # LSTM ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    n_steps=min(48, len(st.session_state.train) // 10),  # ì‹œí€€ìŠ¤ ê¸¸ì´
                    lstm_units=[50, 50],
                    dropout_rate=0.2,
                    epochs=100,
                    batch_size=32,
                    validation_split=0.1
                )
            else:
                # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test
                )
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
            forecasts[model.name] = forecast
            metrics[model.name] = model_metrics
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            completed_models += 1
            progress_bar.progress(completed_models / total_models)
            
        except Exception as e:
            st.error(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥
    if forecasts:
        st.session_state.forecasts = forecasts
        st.session_state.metrics = metrics
        st.session_state.models_trained = True
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        rmse_values = {model: metrics[model]['RMSE'] for model in metrics}
        st.session_state.best_model = min(rmse_values.items(), key=lambda x: x[1])[0]
        
        status_text.text("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    else:
        st.error("ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í•¨ìˆ˜
def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì•± í—¤ë” ë Œë”ë§
    render_header()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š Analysis Settings")
    
    # ë°ì´í„° ë¡œë“œ ë°©ì‹ ì„ íƒ
    data_source = st.sidebar.radio(
        "Select Data Source",
        ["APIì—ì„œ ê°€ì ¸ì˜¤ê¸°", "íŒŒì¼ ì—…ë¡œë“œ"],
        key="data_source",
        on_change=on_data_source_change
    )
    
    # ë°ì´í„° ë¡œë“œ
    if data_source == "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°":
        st.sidebar.subheader("API Settings")
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        today = datetime.now()
        default_end_date = today.strftime("%Y-%m-%d")
        default_start_date = (today - timedelta(days=30)).strftime("%Y-%m-%d")
        
        start_date = st.sidebar.date_input(
            "Start Date",
            datetime.strptime(default_start_date, "%Y-%m-%d")
        )
        
        end_date = st.sidebar.date_input(
            "End Date",
            datetime.strptime(default_end_date, "%Y-%m-%d")
        )
        
        if st.sidebar.button("Get Data"):
            with st.spinner("Getting data from Seoul City API..."):
                df = load_data(
                    start_date=start_date.strftime("%Y-%m-%d"),
                    end_date=end_date.strftime("%Y-%m-%d")
                )
                if df is not None and not df.empty:
                    st.session_state.df = df
    else:
        st.sidebar.subheader("File Upload")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.sidebar.file_uploader("Upload CSV File", type=["csv"])
        
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            st.session_state.df = df
        else:
            # ê¸°ì¡´ íŒŒì¼ ì‚¬ìš©
            if os.path.exists(app_config.DEFAULT_DATA_FILE):
                use_existing = st.sidebar.checkbox("Use Existing Data", value=True)
                if use_existing:
                    df = load_data(file_path=app_config.DEFAULT_DATA_FILE)
                    if df is not None and not df.empty:
                        st.session_state.df = df
            else:
                st.sidebar.warning("No saved data file found. Please upload a file or get data from API.")
    
    # ë°ì´í„°ê°€ ë¡œë“œë˜ë©´ ë¶„ì„ ì‹œì‘
    if st.session_state.df is not None and not st.session_state.df.empty:
        # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“‹ Data Preview", expanded=True):
            st.write(st.session_state.df.head())
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Data Size:** {st.session_state.df.shape[0]} rows Ã— {st.session_state.df.shape[1]} columns")
                st.write(f"**Period:** {st.session_state.df['MSRDT'].min()} ~ {st.session_state.df['MSRDT'].max()}")
            
            with col2:
                if 'MSRSTE_NM' in st.session_state.df.columns:
                    st.write(f"**Number of Stations:** {st.session_state.df['MSRSTE_NM'].nunique()}")
                    st.write(f"**Station List:** {', '.join(sorted(st.session_state.df['MSRSTE_NM'].unique()))}")
        
        # ë¶„ì„ ì˜µì…˜ ì„¤ì •
        st.sidebar.subheader("ğŸ” Analysis Options")
        
        # ì¸¡ì •ì†Œ ì„ íƒ
        if 'MSRSTE_NM' in st.session_state.df.columns:
            stations = ['ì „ì²´ í‰ê· '] + sorted(st.session_state.df['MSRSTE_NM'].unique().tolist())
            selected_station = st.sidebar.selectbox(
                "Select Station", 
                stations,
                index=0 if st.session_state.selected_station is None else stations.index(st.session_state.selected_station if st.session_state.selected_station else "ì „ì²´ í‰ê· ")
            )
            
            if selected_station == 'ì „ì²´ í‰ê· ':
                st.session_state.selected_station = None
            else:
                st.session_state.selected_station = selected_station
        else:
            st.session_state.selected_station = None
            st.sidebar.info("No station information available.")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        numeric_columns = st.session_state.df.select_dtypes(include=np.number).columns.tolist()
        target_options = [col for col in numeric_columns if col in ['PM10', 'PM25', 'O3', 'NO2', 'CO', 'SO2']]
        
        if not target_options:
            target_options = numeric_columns
        
        if target_options:
            selected_target = st.sidebar.selectbox(
                "Select Variable", 
                target_options,
                index=0 if st.session_state.selected_target is None else target_options.index(st.session_state.selected_target)
            )
            st.session_state.selected_target = selected_target
        else:
            st.error("No numeric variables available for analysis.")
            return
        
        # ì‹œë¦¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸
        update_series()
        
        # ì‹œê³„ì—´ ë¶„ì„ íƒ­
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ì‹œê³„ì—´ ì‹œê°í™”", 
            "ì‹œê³„ì—´ ë¶„í•´", 
            "ì •ìƒì„± & ACF/PACF", 
            "ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡",
            "LLM ë¶„ì„"
        ])
        
        with tab1:
            # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
            st.subheader("ğŸ“ˆ Time Series Visualization")
            
            # ì„ íƒí•œ ì¸¡ì •ì†Œì™€ ë³€ìˆ˜ì— ëŒ€í•œ ì‹œê³„ì—´ ê·¸ë˜í”„
            station_text = f"{st.session_state.selected_station} " if st.session_state.selected_station else "Seoul City Overall "
            fig = visualizer.plot_timeseries(
                st.session_state.series,
                title=f"{station_text}{st.session_state.selected_target} Time Series Data",
                ylabel=st.session_state.selected_target
            )
            st.pyplot(fig)
        
        with tab2:
            # ì‹œê³„ì—´ ë¶„í•´
            st.subheader("ğŸ”„ Time Series Decomposition")
            
            # ê³„ì ˆì„± ì£¼ê¸° ì„ íƒ
            min_period = 2
            max_period = min(len(st.session_state.series) // 2, 168)  # ìµœëŒ€ ì¼ì£¼ì¼(168ì‹œê°„) ë˜ëŠ” ë°ì´í„° ê¸¸ì´ì˜ ì ˆë°˜
            
            period = st.slider(
                "Seasonality Period (hours)",
                min_value=min_period,
                max_value=max_period,
                value=st.session_state.period
            )
            st.session_state.period = period
            
            try:
                # ì‹œê³„ì—´ ë¶„í•´ ìˆ˜í–‰
                st.session_state.decomposition = data_processor.decompose_timeseries(st.session_state.series, period)
                
                # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
                decomp_fig = visualizer.plot_decomposition(st.session_state.decomposition)
                st.pyplot(decomp_fig)
            except Exception as e:
                st.error(f"Error in time series decomposition: {str(e)}")
        
        with tab3:
            # ì •ìƒì„± ê²€ì •
            st.subheader("ğŸ” Stationarity Test")
            
            try:
                # ì •ìƒì„± ê²€ì • ìˆ˜í–‰
                st.session_state.stationarity_result = data_processor.check_stationarity(st.session_state.series)
                
                # ì •ìƒì„± ê²€ì • ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**ADF Statistic:** {st.session_state.stationarity_result['test_statistic']:.4f}")
                    st.write(f"**p-value:** {st.session_state.stationarity_result['p_value']:.4f}")
                    
                    # ì •ìƒì„± ì—¬ë¶€
                    if st.session_state.stationarity_result['is_stationary']:
                        st.success("The time series data is stationary.")
                    else:
                        st.warning("The time series data is not stationary.")
                
                with col2:
                    st.write("**Critical Values:**")
                    for key, value in st.session_state.stationarity_result['critical_values'].items():
                        st.write(f"{key}: {value:.4f}")
                
                # ACF, PACF ë¶„ì„
                st.subheader("ğŸ“Š ACF/PACF Analysis")
                
                # ACF, PACF ê³„ì‚°
                st.session_state.acf_values, st.session_state.pacf_values = data_processor.get_acf_pacf(st.session_state.series)
                
                acf_pacf_fig = visualizer.plot_acf_pacf(st.session_state.acf_values, st.session_state.pacf_values)
                st.pyplot(acf_pacf_fig)
            except Exception as e:
                st.error(f"Error in stationarity test: {str(e)}")
        
        with tab4:
            # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            st.subheader("ğŸ¤– Model Training & Prediction")
            
            # ì‚¬ì´ë“œë°”ì— í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ì˜µì…˜ ì¶”ê°€
            test_size = st.sidebar.slider(
                "Test Data Ratio",
                min_value=0.1,
                max_value=0.5,
                value=st.session_state.test_size,
                step=0.05
            )
            st.session_state.test_size = test_size
            
            # ëª¨ë¸ ì„ íƒ
            model_factory = get_model_factory()
            
            if model_factory is None:
                st.error("Model factory loading failed. May be pmdarima compatibility issue.")
                st.error("Try running the following command:")
                st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
            else:
                available_models = model_factory.get_all_available_models()
                
                selected_models = st.sidebar.multiselect(
                    "Select Models",
                    available_models,
                    default=available_models[:2] if not st.session_state.selected_models else st.session_state.selected_models
                )
                st.session_state.selected_models = selected_models
                
                # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ë²„íŠ¼
                if st.button("Start Model Training & Prediction"):
                    if not selected_models:
                        st.warning("Please select at least one model.")
                    else:
                        with st.spinner("Training models..."):
                            train_models()
            
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼ í‘œì‹œ
            if st.session_state.models_trained and st.session_state.forecasts:
                # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“Š Forecast Comparison")
                comparison_fig = visualizer.plot_forecast_comparison(
                    st.session_state.train, 
                    st.session_state.test, 
                    st.session_state.forecasts
                )
                st.pyplot(comparison_fig)
                
                # ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“ˆ Model Performance Comparison")
                metrics_fig = visualizer.plot_metrics_comparison(st.session_state.metrics)
                st.pyplot(metrics_fig)
                
                # ë©”íŠ¸ë¦­ í‘œ í‘œì‹œ
                st.subheader("ğŸ“‹ Model Performance Metrics")
                metrics_df = pd.DataFrame({model: st.session_state.metrics[model] for model in st.session_state.metrics})
                st.write(metrics_df)
                
                # ìµœì  ëª¨ë¸ ì„ íƒ
                if st.session_state.best_model:
                    st.success(f"Best Model (based on RMSE): {st.session_state.best_model}")
                
                # ëª¨ë¸ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸
                st.subheader("ğŸ” Model Interpretation & Insights")
                
                st.markdown(f"""
                ### ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼
                
                1. **ë°ì´í„° íŠ¹ì„±**:
                   - ì„ íƒí•œ ë³€ìˆ˜ ({st.session_state.selected_target})ëŠ” ëšœë ·í•œ ì¼ë³„ ë° ì£¼ë³„ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.
                   - ë¶„í•´ ê²°ê³¼ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, {st.session_state.period}ì‹œê°„ ì£¼ê¸°ì˜ ê³„ì ˆì„±ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
                
                2. **ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ**:
                   - {st.session_state.best_model} ëª¨ë¸ì´ RMSE ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
                   - ëª¨ë¸ íŠ¹ì„±:
                     - ARIMA: ì‹œê³„ì—´ ë°ì´í„°ì˜ ìê¸°ìƒê´€ì„±ì„ í™œìš©í•œ í†µê³„ì  ëª¨ë¸
                     - ì§€ìˆ˜í‰í™œë²•: ìµœê·¼ ê´€ì¸¡ê°’ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë°©ë²•
                     - Prophet: íŠ¸ë Œë“œ, ê³„ì ˆì„±, ê³µíœ´ì¼ íš¨ê³¼ë¥¼ ê³ ë ¤í•œ Facebookì˜ ì‹œê³„ì—´ ëª¨ë¸
                     - LSTM: ìˆœí™˜ ì‹ ê²½ë§ì„ í™œìš©í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸
                
                3. **ì ìš© ê°€ëŠ¥ì„±**:
                   - ì´ ì˜ˆì¸¡ ëª¨ë¸ì€ ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ì‹œìŠ¤í…œ ê°œë°œì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                   - ë¯¸ì„¸ë¨¼ì§€ ë†ë„ê°€ ë†’ì•„ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹œì ì„ ì˜ˆì¸¡í•˜ì—¬ ì‹œë¯¼ ê±´ê°• ë³´í˜¸ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                # ì„ íƒí•œ ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„
                if st.session_state.best_model in st.session_state.forecasts:
                    st.subheader(f"ğŸ“ˆ Best Model ({st.session_state.best_model}) Detailed Analysis")
                    
                    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
                    best_forecast = st.session_state.forecasts[st.session_state.best_model]
                    
                    # ì”ì°¨ ë¶„ì„
                    residuals_fig = visualizer.plot_residuals(st.session_state.test, best_forecast)
                    st.pyplot(residuals_fig)
        with tab5:
            # LLM ë¶„ì„ íƒ­
            st.subheader("ğŸ¤– LLM ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„")
            
            with st.expander("ğŸ“Š LLM ë¶„ì„ ì„¤ì •", expanded=True):
                st.info("Ollama ì„œë²„ë¥¼ í†µí•´ Gemma3:27b ëª¨ë¸ë¡œ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            def check_analysis_ready():
                """
                LLM ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì™€ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                """
                # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì™€ í‰ê°€ ì§€í‘œë¥¼ ìš°ì„  í™•ì¸
                if not hasattr(st.session_state, 'forecasts') or not st.session_state.forecasts:
                    return False, "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'metrics') or not st.session_state.metrics:
                    return False, "ëª¨ë¸ í‰ê°€ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'best_model') or st.session_state.best_model is None:
                    return False, "ìµœì  ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                
                # ì‹œê³„ì—´ ë°ì´í„°ëŠ” í•„ìˆ˜ í™•ì¸
                if not hasattr(st.session_state, 'series') or st.session_state.series is None:
                    return False, "ì‹œê³„ì—´ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                
                # train/test ë°ì´í„°ëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ì§„í–‰
                if not hasattr(st.session_state, 'train') or st.session_state.train is None or not hasattr(st.session_state, 'test') or st.session_state.test is None:
                    st.warning("í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, ëª¨ë¸ ê²°ê³¼ê°€ ìˆìœ¼ë¯€ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                
                return True, "ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ"
            
            # LLM ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
            if st.button("LLM ë¶„ì„ ì‹œì‘", type="primary"):
                
                # ë°ì´í„° ë° ëª¨ë¸ í•™ìŠµ ìƒíƒœ í™•ì¸
                is_ready, message = check_analysis_ready()
                
                if not is_ready:
                    st.warning(message)
                else:
                    with st.spinner("LLMì„ í†µí•´ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            # LLM ì—°ê²° ê°ì²´ ì´ˆê¸°í™”
                            from utils.llm_connector import LLMConnector
                            from prompts.time_series_analysis_prompt import TIME_SERIES_ANALYSIS_PROMPT
                            
                            llm_connector = LLMConnector(base_url=OLLAMA_SERVER, model=OLLAMA_MODEL)
                            
                            # ë°ì´í„° ì •ë³´ ìˆ˜ì§‘ - ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ
                            data_info = {
                                "target_variable": st.session_state.selected_target,
                                "station": st.session_state.selected_station if hasattr(st.session_state, 'selected_station') else None,
                                "seasonality_period": st.session_state.period if hasattr(st.session_state, 'period') else None,
                                "data_range": {
                                    "total_points": len(st.session_state.series),
                                },
                                "date_range": {
                                    "start": str(st.session_state.series.index.min()),
                                    "end": str(st.session_state.series.index.max())
                                },
                                "value_stats": {
                                    "min": float(st.session_state.series.min()),
                                    "max": float(st.session_state.series.max()),
                                    "mean": float(st.session_state.series.mean()),
                                    "std": float(st.session_state.series.std())
                                }
                            }

                            # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            if hasattr(st.session_state, 'train') and st.session_state.train is not None:
                                data_info["data_range"]["train_points"] = len(st.session_state.train)

                            if hasattr(st.session_state, 'test') and st.session_state.test is not None:
                                data_info["data_range"]["test_points"] = len(st.session_state.test)
                            
                            # ì •ìƒì„± ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                            if (hasattr(st.session_state, 'stationarity_result') 
                                and st.session_state.stationarity_result is not None):
                                try:
                                    data_info["stationarity"] = {
                                        "is_stationary": bool(st.session_state.stationarity_result["is_stationary"]),
                                        "p_value": float(st.session_state.stationarity_result["p_value"]),
                                        "test_statistic": float(st.session_state.stationarity_result["test_statistic"])
                                    }
                                except (KeyError, TypeError):
                                    # ì •ìƒì„± ì •ë³´ì— í•„ìš”í•œ í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                                    pass
                            
                            # ë¶„í•´ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ, ìš”ì•½ ì •ë³´ë§Œ)
                            if (hasattr(st.session_state, 'decomposition') 
                                and st.session_state.decomposition is not None):
                                try:
                                    decomp_info = {}
                                    for comp_name, comp_data in st.session_state.decomposition.items():
                                        if comp_name != 'observed' and comp_data is not None:  # ì›ë³¸ ë°ì´í„°ëŠ” ì œì™¸
                                            clean_data = comp_data.dropna()
                                            if not clean_data.empty:
                                                decomp_info[comp_name] = {
                                                    "min": float(clean_data.min()),
                                                    "max": float(clean_data.max()),
                                                    "mean": float(clean_data.mean())
                                                }
                                    
                                    if decomp_info:  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                                        data_info["decomposition"] = decomp_info
                                except Exception as e:
                                    st.warning(f"ë¶„í•´ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œë¨): {e}")
                            
                            # ëª¨ë¸ ê²°ê³¼ ì •ë³´ ìˆ˜ì§‘
                            model_results = {
                                "best_model": st.session_state.best_model,
                                "models": {}
                            }
                            
                            # ê° ëª¨ë¸ì˜ ë©”íŠ¸ë¦­ ì •ë³´ ì¶”ê°€
                            for model_name, metrics in st.session_state.metrics.items():
                                model_results["models"][model_name] = {
                                    "metrics": {}
                                }
                                for metric_name, metric_value in metrics.items():
                                    # NaN ê°’ ì²˜ë¦¬
                                    if pd.isna(metric_value):
                                        model_results["models"][model_name]["metrics"][metric_name] = None
                                    else:
                                        model_results["models"][model_name]["metrics"][metric_name] = float(metric_value)
                                
                                # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ í†µê³„ ì¶”ê°€
                                if model_name in st.session_state.forecasts:
                                    forecast = st.session_state.forecasts[model_name]
                                    if forecast is not None and len(forecast) > 0:
                                        model_results["models"][model_name]["forecast_stats"] = {
                                            "min": float(np.min(forecast)),
                                            "max": float(np.max(forecast)),
                                            "mean": float(np.mean(forecast)),
                                            "std": float(np.std(forecast))
                                        }
                            
                            # LLM ë¶„ì„ ìš”ì²­
                            analysis_result = llm_connector.analyze_time_series(
                                data_info,
                                model_results,
                                TIME_SERIES_ANALYSIS_PROMPT
                            )
                            
                            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            st.markdown(analysis_result)
                            
                            # ì„¸ì…˜ ìƒíƒœì— ë¶„ì„ ê²°ê³¼ ì €ì¥
                            st.session_state.llm_analysis = analysis_result
                            
                            # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                            st.download_button(
                                label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                                data=analysis_result,
                                file_name="time_series_analysis_report.md",
                                mime="text/markdown"
                            )
                            
                        except Exception as e:
                            st.error(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            import traceback
                            st.error(traceback.format_exc())

            # ì´ì „ì— ë¶„ì„í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            elif hasattr(st.session_state, 'llm_analysis') and st.session_state.llm_analysis:
                st.markdown(st.session_state.llm_analysis)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                    data=st.session_state.llm_analysis,
                    file_name="time_series_analysis_report.md",
                    mime="text/markdown"
                )
    else:
        st.info("Please upload data or get data from API to start analysis.")

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
