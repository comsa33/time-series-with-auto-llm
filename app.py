"""
ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„ ë©”ì¸ Streamlit ì•±
"""
import os
import psutil
import time
import random
import warnings
from datetime import datetime, timedelta

import streamlit as st
import pandas as pd
import numpy as np

from config.settings import app_config
from utils.data_reader import get_seoul_air_quality
from utils.data_processor import (
    cached_preprocess_data,
    cached_train_test_split,
    cached_decompose_timeseries,
    cached_check_stationarity,
    cached_get_acf_pacf
)
from utils.visualizer import (
    cached_plot_timeseries,
    cached_plot_decomposition,
    cached_plot_acf_pacf,
    cached_plot_forecast_comparison,
    cached_plot_metrics_comparison,
    cached_plot_residuals
)
from utils.llm_connector import LLMConnector
from prompts.time_series_analysis_prompt import TIME_SERIES_ANALYSIS_PROMPT

import os
# GPU ì‚¬ìš© ë¹„í™œì„±í™” (CPU ëª¨ë“œë§Œ ì‚¬ìš©)
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
# TensorFlow ë¡œê·¸ ë ˆë²¨ ì¡°ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=app_config.APP_TITLE,
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


def initialize_session_state():
    """í•„ìš”í•œ ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”"""
    # ê¸°ë³¸ ë³€ìˆ˜ë“¤
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'data_source' not in st.session_state:
        st.session_state.data_source = "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°"
    if 'selected_station' not in st.session_state:
        st.session_state.selected_station = None
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    if 'series' not in st.session_state:
        st.session_state.series = None
    if 'train' not in st.session_state:
        st.session_state.train = None
    if 'test' not in st.session_state:
        st.session_state.test = None
    if 'period' not in st.session_state:
        st.session_state.period = 24
    if 'decomposition' not in st.session_state:
        st.session_state.decomposition = None
    if 'stationarity_result' not in st.session_state:
        st.session_state.stationarity_result = None
    if 'acf_values' not in st.session_state:
        st.session_state.acf_values = None
    if 'pacf_values' not in st.session_state:
        st.session_state.pacf_values = None
    if 'forecasts' not in st.session_state:
        st.session_state.forecasts = {}
    if 'metrics' not in st.session_state:
        st.session_state.metrics = {}
    if 'models_trained' not in st.session_state:
        st.session_state.models_trained = False
    if 'selected_models' not in st.session_state:
        st.session_state.selected_models = []
    if 'test_size' not in st.session_state:
        st.session_state.test_size = app_config.DEFAULT_TEST_SIZE
    if 'best_model' not in st.session_state:
        st.session_state.best_model = None
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0
    if 'prev_target' not in st.session_state:
        st.session_state.prev_target = None
    if 'prev_station' not in st.session_state:
        st.session_state.prev_station = None

# ëª¨ë¸ íŒ©í† ë¦¬ ë™ì  ë¡œë“œ
@st.cache_resource
def get_model_factory():
    """
    ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    í•„ìš”í•  ë•Œë§Œ importí•˜ì—¬ ì‹œì‘ ì‹œ pmdarima ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        from models.model_factory import ModelFactory
        return ModelFactory()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”: pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return None

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data(ttl=3600)
def load_data(file_path=None, start_date=None, end_date=None):
    """
    CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        if file_path and os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            return df
        else:
            st.info("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            
            if not start_date or not end_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ í•œ ë‹¬
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            
            df = get_seoul_air_quality(app_config.SEOUL_API_KEY, start_date, end_date)
            
            if df is not None and not df.empty:
                # íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(app_config.DATA_DIR, exist_ok=True)
                df.to_csv(app_config.DEFAULT_DATA_FILE, index=False, encoding='utf-8-sig')
                st.success(f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {app_config.DEFAULT_DATA_FILE}")
            
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì•± í—¤ë” í•¨ìˆ˜
def render_header():
    """
    ì•± í—¤ë” ë Œë”ë§
    """
    st.title("ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„")
    st.markdown("ì„œìš¸ì‹œ IoT ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹œê³„ì—´ ë¶„ì„ ì•±")
    
    # í™•ì¥ ê°€ëŠ¥í•œ ì•± ì†Œê°œ
    with st.expander("ğŸ“Œ ì•± ì†Œê°œ ë° ì‚¬ìš© ë°©ë²•"):
        st.markdown("""
        ### ğŸ“Œ ì•± ì†Œê°œ
        ì´ ì•±ì€ ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

        ### ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥
        1. **ë°ì´í„° íƒìƒ‰**: ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™” ì œê³µ
        2. **ì‹œê³„ì—´ ë¶„í•´**: ì¶”ì„¸(Trend), ê³„ì ˆì„±(Seasonality), ë¶ˆê·œì¹™ì„±(Irregularity) ë¶„ì„
        3. **ëª¨ë¸ ë¹„êµ**: ARIMA/SARIMA, ì§€ìˆ˜í‰í™œë²•, Prophet, LSTM ë“± ë‹¤ì–‘í•œ ì˜ˆì¸¡ ëª¨ë¸ ì§€ì›
        4. **ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€**: RMSE, MAE, RÂ² ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê¸°ë°˜ í‰ê°€

        ### ğŸ› ï¸ ì‚¬ìš© ë°©ë²•
        1. ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” API ìˆ˜ì§‘ ì˜µì…˜ ì„ íƒ
        2. ë¶„ì„í•  ì¸¡ì •ì†Œì™€ ë³€ìˆ˜(PM10, PM25 ë“±) ì„ íƒ
        3. ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜ ì„¤ì • í›„ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        4. ê²°ê³¼ íƒ­ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
        """)

# ë°ì´í„° ì†ŒìŠ¤ ë³€ê²½ ì½œë°±
def on_data_source_change():
    st.session_state.df = None
    st.session_state.series = None
    st.session_state.train = None
    st.session_state.test = None
    st.session_state.models_trained = False


# ì¸¡ì •ì†Œ/íƒ€ê²Ÿ ë³€ê²½ ì½œë°±
def update_series():
    """ì‹œê³„ì—´ ë°ì´í„° ì—…ë°ì´íŠ¸ í•¨ìˆ˜ - ìºì‹± í™œìš©"""
    if st.session_state.df is not None:
        # ìºì‹±ëœ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
        st.session_state.series = cached_preprocess_data(
            st.session_state.df, 
            st.session_state.selected_target, 
            st.session_state.selected_station
        )
        
        # ì´ì „ ê²°ê³¼ì™€ í˜„ì¬ ì„¤ì •ì˜ í˜¸í™˜ì„± í™•ì¸
        if st.session_state.models_trained:
            # íƒ€ê²Ÿ ë³€ìˆ˜ë‚˜ ì¸¡ì •ì†Œê°€ ë³€ê²½ë˜ë©´ ê²°ê³¼ ì´ˆê¸°í™”
            if ('prev_target' in st.session_state and 
                st.session_state.prev_target != st.session_state.selected_target):
                st.session_state.models_trained = False
                st.session_state.forecasts = {}
                st.session_state.metrics = {}
            
            if ('prev_station' in st.session_state and 
                st.session_state.prev_station != st.session_state.selected_station):
                st.session_state.models_trained = False
                st.session_state.forecasts = {}
                st.session_state.metrics = {}
        
        # í˜„ì¬ ì„ íƒ ì €ì¥
        st.session_state.prev_target = st.session_state.selected_target
        st.session_state.prev_station = st.session_state.selected_station


# ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ìºì‹±í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
# ARIMA ëª¨ë¸ìš© ìºì‹± í•¨ìˆ˜
@st.cache_data(ttl=3600)
def cached_train_arima(train_data_key, test_data_key, seasonal, m, **kwargs):
    """ARIMA ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    try:
        model_factory = get_model_factory()
        if model_factory is None:
            return None, None
        
        model = model_factory.get_model('arima')
        # ëª¨ë“  ì¶”ê°€ íŒŒë¼ë¯¸í„°ë¥¼ model.fit_predict_evaluateë¡œ ì „ë‹¬
        forecast, metrics = model.fit_predict_evaluate(
            st.session_state.train, 
            st.session_state.test,
            seasonal=seasonal,
            m=m,
            **kwargs  # ì—¬ê¸°ì„œ arima_paramsì˜ ë‚´ìš©ì´ ì „ë‹¬ë¨
        )
        return forecast, metrics
    except Exception as e:
        st.error(f"ARIMA ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, None

# Prophet ëª¨ë¸ìš© ìºì‹± í•¨ìˆ˜
@st.cache_data(ttl=3600)
def cached_train_prophet(train_data_key, test_data_key, **kwargs):
    """Prophet ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    try:
        model_factory = get_model_factory()
        if model_factory is None:
            return None, None
        
        model = model_factory.get_model('prophet')
        forecast, metrics = model.fit_predict_evaluate(
            st.session_state.train, 
            st.session_state.test,
            **kwargs  # prophet_paramsì˜ ë‚´ìš©ì´ ì—¬ê¸°ë¡œ ì „ë‹¬ë¨
        )
        return forecast, metrics
    except Exception as e:
        st.error(f"Prophet ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, None

# LSTM ëª¨ë¸ìš© ìºì‹± í•¨ìˆ˜
@st.cache_data(ttl=3600)
def cached_train_lstm(train_data_key, test_data_key, **kwargs):
    """LSTM ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    try:
        model_factory = get_model_factory()
        if model_factory is None:
            return None, None
        
        model = model_factory.get_model('lstm')
        forecast, metrics = model.fit_predict_evaluate(
            st.session_state.train, 
            st.session_state.test,
            **kwargs  # ëª¨ë“  lstm_paramsê°€ ì—¬ê¸°ë¡œ ì „ë‹¬ë¨
        )
        return forecast, metrics
    except Exception as e:
        st.error(f"LSTM ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, None

@st.cache_data(ttl=3600)
def cached_train_exp_smoothing(train_data_key, test_data_key, seasonal_periods):
    try:
        model_factory = get_model_factory()
        if model_factory is None:
            return None, None
        
        model = model_factory.get_model('exp_smoothing')
        forecast, metrics = model.fit_predict_evaluate(
            st.session_state.train, 
            st.session_state.test,
            seasonal_periods=seasonal_periods
        )
        return forecast, metrics
    except Exception as e:
        st.error(f"ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, None

def safe_len(obj, default=10):
    """Noneì´ ì•„ë‹Œ ê°ì²´ì˜ ê¸¸ì´ë¥¼ ì•ˆì „í•˜ê²Œ ë°˜í™˜, Noneì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜"""
    if obj is not None:
        return len(obj)
    return default

def train_models():
    """ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ í•¨ìˆ˜ - ìºì‹± í™œìš©"""
    # í˜„ì¬ ë³µì¡ë„ ì„¤ì • í™•ì¸
    complexity = st.session_state.get('complexity', 'ê°„ë‹¨ (ë¹ ë¦„, ì €ë©”ëª¨ë¦¬)')
    

    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    st.session_state.train, st.session_state.test = cached_train_test_split(
        st.session_state.series, 
        st.session_state.test_size
    )
    
    # ë°ì´í„° í‚¤ ìƒì„± (ìºì‹±ìš©)
    train_data_key = hash(tuple(st.session_state.train.values.tolist()))
    test_data_key = hash(tuple(st.session_state.test.values.tolist()))

    # ë³µì¡ë„ë³„ íŒŒë¼ë¯¸í„° ì„¤ì •
    if complexity == 'ê°„ë‹¨ (ë¹ ë¦„, ì €ë©”ëª¨ë¦¬)':
        arima_params = {
            'max_p': 1, 'max_q': 1, 'max_P': 0, 'max_Q': 0,
            'stepwise': True, 'n_jobs': 1
        }
        lstm_params = {
            'n_steps': min(24, safe_len(st.session_state.train, 100) // 20),
            'lstm_units': [32],
            'epochs': 30
        }
        prophet_params = {
            'daily_seasonality': False,
            'weekly_seasonality': True,
            'changepoint_prior_scale': 0.01
        }
    elif complexity == 'ì¤‘ê°„':
        arima_params = {
            'max_p': 2, 'max_q': 2, 'max_P': 1, 'max_Q': 1,
            'stepwise': True, 'n_jobs': 1
        }
        lstm_params = {
            'n_steps': min(48, safe_len(st.session_state.train, 100) // 10),
            'lstm_units': [50],
            'epochs': 50
        }
        prophet_params = {
            'daily_seasonality': True,
            'weekly_seasonality': True,
            'changepoint_prior_scale': 0.05
        }
    else:  # ë³µì¡ (ì •í™•ë„ ë†’ìŒ, ê³ ë©”ëª¨ë¦¬)
        arima_params = {
            'max_p': 5, 'max_q': 5, 'max_P': 2, 'max_Q': 2,
            'stepwise': True, 'n_jobs': 1
        }
        lstm_params = {
            'n_steps': min(72, safe_len(st.session_state.train, 100) // 8),
            'lstm_units': [50, 50],
            'epochs': 100
        }
        prophet_params = {
            'daily_seasonality': True,
            'weekly_seasonality': True,
            'yearly_seasonality': True,
            'changepoint_prior_scale': 0.05
        }
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
    forecasts = {}
    metrics = {}
    
    # ëª¨ë¸ ê°œìˆ˜
    total_models = len(st.session_state.selected_models)
    completed_models = 0
    
    # ê° ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    for model_type in st.session_state.selected_models:
        status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ë³„ ìºì‹±ëœ í•™ìŠµ í•¨ìˆ˜ í˜¸ì¶œ
            if model_type == 'arima':
                forecast, model_metrics = cached_train_arima(
                    train_data_key, 
                    test_data_key,
                    seasonal=True,
                    m=st.session_state.period,
                    **arima_params
                )
            elif model_type == 'exp_smoothing':
                forecast, model_metrics = cached_train_exp_smoothing(
                    train_data_key, 
                    test_data_key,
                    seasonal_periods=st.session_state.period
                )
            elif model_type == 'prophet':
                forecast, model_metrics = cached_train_prophet(
                    train_data_key, 
                    test_data_key,
                    **prophet_params
                )
            elif model_type == 'lstm':
                n_steps = min(48, len(st.session_state.train) // 10)
                forecast, model_metrics = cached_train_lstm(
                    train_data_key, 
                    test_data_key,
                    **lstm_params
                )
            else:
                # ì¼ë°˜ì ì¸ ëª¨ë¸ ì²˜ë¦¬
                model_factory = get_model_factory()
                model = model_factory.get_model(model_type)
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test
                )
            
            # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì €ì¥
            if forecast is not None and model_metrics is not None:
                forecasts[model_metrics.get('name', model_type)] = forecast
                metrics[model_metrics.get('name', model_type)] = model_metrics
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            completed_models += 1
            progress_bar.progress(completed_models / total_models)
            
        except Exception as e:
            st.error(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥
    if forecasts:
        st.session_state.forecasts = forecasts
        st.session_state.metrics = metrics
        st.session_state.models_trained = True
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        rmse_values = {model: metrics[model]['RMSE'] for model in metrics}
        st.session_state.best_model = min(rmse_values.items(), key=lambda x: x[1])[0]
        
        status_text.text("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    else:
        st.error("ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ì•± ì‹œì‘ ì‹œ ìºì‹œ ì •ë¦¬ í•¨ìˆ˜ (main() í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€)
def clear_expired_caches():
    """
    ì˜¤ë˜ëœ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. 
    ë§¤ ìš”ì²­ì˜ 5% í™•ë¥ ë¡œ ì‹¤í–‰ë˜ì–´ ì ì§„ì ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    
    if random.random() < 0.05:  # 5% í™•ë¥ ë¡œ ì‹¤í–‰
        cache_dir = os.path.join(os.path.expanduser("~"), ".streamlit/cache")
        if os.path.exists(cache_dir):
            try:
                # 24ì‹œê°„ ì´ìƒ ëœ ìºì‹œ íŒŒì¼ ì‚­ì œ
                current_time = time.time()
                for file in os.listdir(cache_dir):
                    file_path = os.path.join(cache_dir, file)
                    if os.path.isfile(file_path):
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                        if current_time - os.path.getmtime(file_path) > 86400:  # 24ì‹œê°„
                            os.remove(file_path)
            except Exception:
                pass  # ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ í•¨ìˆ˜
def show_memory_usage():
    
    process = psutil.Process(os.getpid())
    memory_usage = process.memory_info().rss / 1024 / 1024  # MB ë‹¨ìœ„
    
    # ì‚¬ì´ë“œë°” í•˜ë‹¨ì— ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    st.sidebar.progress(min(memory_usage / 4000, 1.0))  # 4GB ê¸°ì¤€
    st.sidebar.text(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f} MB")
    
    if memory_usage > 3500:  # 3.5GB ì´ìƒì¼ ë•Œ ê²½ê³ 
        st.sidebar.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ëª¨ë¸ì„ ì œê±°í•˜ê±°ë‚˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


# ë©”ì¸ í•¨ìˆ˜
def main():
    
    # ìºì‹œ ì •ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
    clear_expired_caches()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì•± í—¤ë” ë Œë”ë§
    render_header()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š ë¶„ì„ ì„¤ì •")

    st.sidebar.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    st.sidebar.subheader("ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„° ë¡œë“œ", help="ì„œìš¸ì‹œ IoT ëŒ€ê¸°ì§ˆ ë°ì´í„° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.")


    # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
    today = datetime.now().date()  # datetime.date ê°ì²´ë¡œ ë³€í™˜
    default_end_date = today
    default_start_date = today - timedelta(days=30)

    st.sidebar.markdown("##### ğŸ“… ë¶„ì„ ê¸°ê°„ ì„ íƒ", help="ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”. (ìµœëŒ€ 30ì¼)")

    date_col1, date_col2 = st.sidebar.columns(2)

    with date_col1:
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            default_start_date
        )
        
    with date_col2:
        # ì‹œì‘ì¼ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ì¢…ë£Œì¼ ê³„ì‚° (30ì¼ ì´ë‚´)
        max_end_date = start_date + timedelta(days=30)
        if today < max_end_date:
            max_end_date = today
            
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            min(default_end_date, max_end_date),
            min_value=start_date,
            max_value=max_end_date
        )

    # ì„ íƒëœ ë‚ ì§œ ë²”ìœ„ ì¼ìˆ˜ ê³„ì‚°
    date_range_days = (end_date - start_date).days

    # ê¸°ê°„ í‘œì‹œ ì •ë³´ ë° ì‹œê°í™”
    progress_value = min(date_range_days / 30, 1.0)
    st.sidebar.progress(progress_value)
    st.sidebar.text(f"ì„ íƒëœ ê¸°ê°„: {date_range_days + 1}ì¼ / ìµœëŒ€ 30ì¼")

    if date_range_days > 25:
        st.sidebar.warning("ë°ì´í„° ì–‘ì´ ë§ì„ìˆ˜ë¡ ë¶„ì„ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼
    if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        with st.spinner("ì„œìš¸ì‹œ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            df = load_data(
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d")
            )
            if df is not None and not df.empty:
                st.session_state.df = df

    st.sidebar.markdown("---")
    
    # ë°ì´í„°ê°€ ë¡œë“œë˜ë©´ ë¶„ì„ ì‹œì‘
    if st.session_state.df is not None and not st.session_state.df.empty:
        # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            # ë°ì´í„° ìƒ˜í”Œ í‘œì‹œ
            st.dataframe(st.session_state.df.head(), use_container_width=True)
            
            # êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown("---")
            
            # ì •ë³´ ì„¹ì…˜ ì œëª©
            st.markdown("### ğŸ“Š ë°ì´í„° ìš”ì•½ ì •ë³´")
            
            # ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì¹´ë“œ (4ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜)
            metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
            
            # 1. ë°ì´í„° í–‰ ìˆ˜
            metric_col1.metric(
                label="ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜",
                value=f"{st.session_state.df.shape[0]:,}",
                help="ì „ì²´ ë°ì´í„° ë ˆì½”ë“œ ìˆ˜",
                border=True
            )
            
            # 2. ë°ì´í„° ì—´ ìˆ˜
            metric_col2.metric(
                label="ğŸ“Š ë°ì´í„° ì—´ ìˆ˜",
                value=f"{st.session_state.df.shape[1]}",
                help="ë°ì´í„°ì…‹ì˜ ì†ì„±(íŠ¹ì„±) ìˆ˜",
                border=True
            )
            
            # 3. ì‹œì‘ ë‚ ì§œ
            start_date = st.session_state.df['MSRDT'].min()
            metric_col3.metric(
                label="ğŸ“… ì‹œì‘ ë‚ ì§œ",
                value=f"{start_date.strftime('%Y-%m-%d')}",
                help="ë°ì´í„°ì˜ ì‹œì‘ ë‚ ì§œ",
                border=True
            )
            
            # 4. ì¢…ë£Œ ë‚ ì§œ
            end_date = st.session_state.df['MSRDT'].max()
            days_diff = (end_date - start_date).days
            metric_col4.metric(
                label="ğŸ“… ì¢…ë£Œ ë‚ ì§œ",
                value=f"{end_date.strftime('%Y-%m-%d')}",
                delta=f"{days_diff}ì¼",
                help="ë°ì´í„°ì˜ ì¢…ë£Œ ë‚ ì§œ (deltaëŠ” ì „ì²´ ê¸°ê°„)",
                border=True
            )
            
            # ì¸¡ì •ì†Œ ì •ë³´ ì„¹ì…˜ (ìˆëŠ” ê²½ìš°ë§Œ)
            if 'MSRSTE_NM' in st.session_state.df.columns:
                # êµ¬ë¶„ì„  ì¶”ê°€
                st.markdown("---")
                st.markdown("### ğŸ“ ì¸¡ì •ì†Œ ì •ë³´")
                
                # ì¸¡ì •ì†Œ ì •ë³´ë¥¼ ìœ„í•œ ë‘ ê°œì˜ ì»¬ëŸ¼ (2:1 ë¹„ìœ¨)
                station_col1, station_col2 = st.columns([2, 1])
                
                with station_col1:
                    # expander ëŒ€ì‹  ì»¨í…Œì´ë„ˆì™€ ì œëª© ì‚¬ìš©
                    st.markdown("#### ğŸ“‹ ì¸¡ì •ì†Œ ëª©ë¡")
                    # êµ¬ë¶„ì„ ìœ¼ë¡œ ì‹œê°ì  ë¶„ë¦¬ íš¨ê³¼
                    st.markdown("<hr style='margin: 5px 0px 15px 0px'>", unsafe_allow_html=True)
                    
                    # ì¸¡ì •ì†Œ ëª©ë¡ì„ í‘œ í˜•íƒœë¡œ í‘œì‹œ (ë” êµ¬ì¡°í™”ëœ í˜•íƒœ)
                    stations = sorted(st.session_state.df['MSRSTE_NM'].unique())
                    
                    # ì¸¡ì •ì†Œ ëª©ë¡ì„ 3ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ (ë” ì½ê¸° ì‰½ê²Œ)
                    cols = st.columns(3)
                    for i, station in enumerate(stations):
                        cols[i % 3].markdown(f"â€¢ {station}")
                
                with station_col2:
                    # ì¸¡ì •ì†Œ ìˆ˜ë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‘œì‹œ
                    num_stations = st.session_state.df['MSRSTE_NM'].nunique()
                    st.metric(
                        label="ğŸ¢ ì¸¡ì •ì†Œ ìˆ˜",
                        value=f"{num_stations}ê°œ",
                        help="ë¶„ì„ ëŒ€ìƒ ì¸¡ì •ì†Œì˜ ì´ ê°œìˆ˜",
                        border=True
                    )
                    
                    # ì¸¡ì • ë¹ˆë„ë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‘œì‹œ (ì‹œê°„ë‹¹, ì¼ë‹¹ ì¸¡ì • íšŸìˆ˜ ë“±)
                    # ì‹œê°„ë‹¹ ì¸¡ì • ë¹ˆë„ ê³„ì‚° (ëŒ€ëµì ì¸ ê°’)
                    hours_span = (end_date - start_date).total_seconds() / 3600
                    records_per_hour = st.session_state.df.shape[0] / max(hours_span, 1)
                    
                    st.metric(
                        label="ğŸ“Š ì¸¡ì • ë¹ˆë„",
                        value=f"{records_per_hour:.1f}íšŒ/ì‹œê°„",
                        help="ì‹œê°„ë‹¹ í‰ê·  ì¸¡ì • ë¹ˆë„",
                        border=True
                    )
                    
                    # ì¶”ê°€ ì •ë³´: ì¸¡ì •ì†Œë³„ ë°ì´í„° ìˆ˜ ë¶„í¬
                    records_per_station = st.session_state.df.groupby('MSRSTE_NM').size().mean()
                    st.metric(
                        label="ğŸ“Š ì¸¡ì •ì†Œë³„ ë°ì´í„°",
                        value=f"{records_per_station:.1f}ê°œ",
                        help="ì¸¡ì •ì†Œë‹¹ í‰ê·  ë°ì´í„° ìˆ˜",
                        border=True
                    )
        
        # ë¶„ì„ ì˜µì…˜ ì„¤ì •
        st.sidebar.subheader("ğŸ” ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜")
        
        # ì¸¡ì •ì†Œ ì„ íƒ
        if 'MSRSTE_NM' in st.session_state.df.columns:
            stations = ['ì „ì²´ í‰ê· '] + sorted(st.session_state.df['MSRSTE_NM'].unique().tolist())
            selected_station = st.sidebar.selectbox(
                "Select Station", 
                stations,
                index=0 if st.session_state.selected_station is None else stations.index(st.session_state.selected_station if st.session_state.selected_station else "ì „ì²´ í‰ê· ")
            )
            
            if selected_station == 'ì „ì²´ í‰ê· ':
                st.session_state.selected_station = None
            else:
                st.session_state.selected_station = selected_station
        else:
            st.session_state.selected_station = None
            st.sidebar.info("ì¸¡ì •ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        numeric_columns = st.session_state.df.select_dtypes(include=np.number).columns.tolist()
        target_options = [col for col in numeric_columns if col in ['PM10', 'PM25', 'O3', 'NO2', 'CO', 'SO2']]
        
        if not target_options:
            target_options = numeric_columns
        
        if target_options:
            selected_target = st.sidebar.selectbox(
                "ë¶„ì„í•  ë³€ìˆ˜ ì„ íƒ", 
                target_options,
                index=5 if st.session_state.selected_target is None else target_options.index(st.session_state.selected_target)
            )
            st.session_state.selected_target = selected_target
        else:
            st.error("ë¶„ì„ ê°€ëŠ¥í•œ ìˆ«ìí˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì‹œë¦¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸
        update_series()
        
        # ì‹œê³„ì—´ ë¶„ì„ íƒ­
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ì‹œê³„ì—´ ì‹œê°í™”", 
            "ì‹œê³„ì—´ ë¶„í•´", 
            "ì •ìƒì„± & ACF/PACF", 
            "ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡",
            "LLM ë¶„ì„"
        ])
        
        with tab1:
            # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
            st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ì‹œê°í™”")
            
            # ìºì‹±ëœ ì‹œê°í™” í•¨ìˆ˜ ì‚¬ìš©
            if st.session_state.series is not None:
                station_text = f"{st.session_state.selected_station} " if st.session_state.selected_station else "Seoul City Overall "
                fig = cached_plot_timeseries(
                    st.session_state.series,
                    title=f"{station_text}{st.session_state.selected_target} ì‹œê³„ì—´ ë°ì´í„°",
                    xlabel="ë‚ ì§œ (Date)",
                    ylabel=st.session_state.selected_target
                )
                st.plotly_chart(fig, use_container_width=True, theme="streamlit")
        
        with tab2:
            # ì‹œê³„ì—´ ë¶„í•´
            st.subheader("ğŸ”„ ì‹œê³„ì—´ ë¶„í•´", help="ì‹œê³„ì—´ ë¶„í•´(Time Series Decomposition)ë€, **ì‹œê³„ì—´ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ëŠ” ì—¬ëŸ¬ ìš”ì†Œ(ì„±ë¶„)**ë¥¼ ë¶„ë¦¬í•´ë‚´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ë” ì˜ ì´í•´í•˜ê³ , ì˜ˆì¸¡ë ¥ ë†’ì€ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ê³„ì ˆì„± ì£¼ê¸° ì„ íƒ
            min_period = 2
            max_period = min(len(st.session_state.series) // 2, 168)  # ìµœëŒ€ ì¼ì£¼ì¼(168ì‹œê°„) ë˜ëŠ” ë°ì´í„° ê¸¸ì´ì˜ ì ˆë°˜
            
            period = st.slider(
                "ê³„ì ˆì„± ì£¼ê¸° (ì‹œê°„ ë‹¨ìœ„)",
                min_value=min_period,
                max_value=max_period,
                value=st.session_state.period,
                help="ê³„ì ˆì„± ì£¼ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì˜ˆ: 24ì‹œê°„ì€ í•˜ë£¨ ì£¼ê¸°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
            )
            st.session_state.period = period
            
            try:
                # ì‹œê³„ì—´ ë¶„í•´ ìˆ˜í–‰
                st.session_state.decomposition = cached_decompose_timeseries(st.session_state.series, period)
                
                # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
                decomp_fig = cached_plot_decomposition(st.session_state.decomposition)
                st.plotly_chart(decomp_fig, use_container_width=True, theme="streamlit")
            except Exception as e:
                st.error(f"ì‹œê³„ì—´ ë¶„í•´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with tab3:
            # ì •ìƒì„± ê²€ì •
            st.subheader("ğŸ” ì •ìƒì„± ê²€ì •", help="ì •ìƒì„± ê²€ì •(Stationarity Test)ì´ë€ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì‹œê°„ì´ ì§€ë‚˜ë„ í†µê³„ì  íŠ¹ì„±ì´ ì¼ì •í•œì§€(=ì •ìƒì¸ì§€) í™•ì¸í•˜ëŠ” ê²€ì •ì…ë‹ˆë‹¤. ì¦‰, í‰ê· , ë¶„ì‚°, ìê¸°ê³µë¶„ì‚° ë“±ì˜ ê°’ì´ ì‹œê°„ì— ë”°ë¼ ë³€í•˜ì§€ ì•ŠëŠ”ì§€ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤")

            try:
                # ì •ìƒì„± ê²€ì • ìˆ˜í–‰
                st.session_state.stationarity_result = cached_check_stationarity(st.session_state.series)
                
                # ì‹œê°ì  êµ¬ë¶„ì„  ì¶”ê°€
                st.markdown("---")
                
                # ì •ìƒì„± ê²°ê³¼ ì»¨í…Œì´ë„ˆ
                with st.container():
                    # ì •ìƒì„± ì—¬ë¶€ ë¨¼ì € í° ê¸€ì”¨ë¡œ í‘œì‹œ
                    if st.session_state.stationarity_result['is_stationary']:
                        st.success("### âœ… ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•©ë‹ˆë‹¤")
                    else:
                        st.warning("### âš ï¸ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                        
                    # ì„¤ëª… ì¶”ê°€
                    with st.expander("ì •ìƒì„± íŒë‹¨ ê¸°ì¤€ ì„¤ëª…", expanded=False):
                        st.markdown("""
                        - **ADF í†µê³„ëŸ‰**ì´ ì„ê³„ê°’ë³´ë‹¤ **ì‘ì„ìˆ˜ë¡** ì •ìƒì„± ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤
                        - **p-ê°’**ì´ 0.05ë³´ë‹¤ **ì‘ìœ¼ë©´** ì •ìƒì„±ì„ ë§Œì¡±í•©ë‹ˆë‹¤
                        - ADF í†µê³„ëŸ‰ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ì„ìˆ˜ë¡, ê·¸ë¦¬ê³  p-ê°’ì´ ì‘ì„ìˆ˜ë¡ ì •ìƒì„± ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤
                        """)
                    
                    # ë©”íŠ¸ë¦­ í‘œì‹œë¥¼ ìœ„í•œ 3ê°œ ì»¬ëŸ¼
                    metric_col1, metric_col2, metric_col3 = st.columns(3)
                    
                    # ADF í†µê³„ëŸ‰ (ì²« ë²ˆì§¸ ë©”íŠ¸ë¦­)
                    test_stat = st.session_state.stationarity_result['test_statistic']
                    critical_1pct = st.session_state.stationarity_result['critical_values']['1%']
                    # ADF í†µê³„ëŸ‰ê³¼ 1% ì„ê³„ê°’ì˜ ì°¨ì´
                    delta_adf = test_stat - critical_1pct
                    
                    # ì‹œê°í™”: ADF í†µê³„ëŸ‰ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì¢‹ì€ ê²ƒì´ë¯€ë¡œ delta_color="inverse" ì‚¬ìš©
                    metric_col1.metric(
                        label="ADF í†µê³„ëŸ‰",
                        value=f"{test_stat:.4f}",
                        delta=f"{delta_adf:.4f}",
                        delta_color="inverse",
                        help="ADF í†µê³„ëŸ‰ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ì„ìˆ˜ë¡ ì •ìƒì„± ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤",
                        border=True
                    )
                    
                    # p-ê°’ (ë‘ ë²ˆì§¸ ë©”íŠ¸ë¦­)
                    p_value = st.session_state.stationarity_result['p_value']
                    # p-ê°’ê³¼ 0.05ì˜ ì°¨ì´
                    delta_p = p_value - 0.05
                    
                    # ì‹œê°í™”: p-ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒì´ë¯€ë¡œ delta_color="inverse" ì‚¬ìš©
                    metric_col2.metric(
                        label="p-ê°’",
                        value=f"{p_value:.4f}",
                        delta=f"{delta_p:.4f}",
                        delta_color="inverse",
                        help="p-ê°’ì´ 0.05ë³´ë‹¤ ì‘ìœ¼ë©´ ì •ìƒì„±ì„ ë§Œì¡±í•©ë‹ˆë‹¤",
                        border=True
                    )
                    
                    # ê´€ì¸¡ ìˆ˜ (ì„¸ ë²ˆì§¸ ë©”íŠ¸ë¦­)
                    num_obs = st.session_state.stationarity_result['num_observations']
                    metric_col3.metric(
                        label="ê´€ì¸¡ ë°ì´í„° ìˆ˜",
                        value=f"{num_obs:,}",
                        help="ì •ìƒì„± ê²€ì •ì— ì‚¬ìš©ëœ ë°ì´í„° ìˆ˜",
                        border=True
                    )
                    
                    # ì„ê³„ê°’ ì¹´ë“œ
                    st.markdown("### ğŸ“Š ì„ê³„ê°’ (Critical Values)")
                    
                    # ì„ê³„ê°’ í‘œì‹œë¥¼ ìœ„í•œ 3ê°œ ì»¬ëŸ¼
                    crit_col1, crit_col2, crit_col3 = st.columns(3)
                    
                    # ê° ì„ê³„ê°’ì„ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‘œì‹œ
                    for i, (key, value) in enumerate(st.session_state.stationarity_result['critical_values'].items()):
                        # ADF í†µê³„ëŸ‰ê³¼ ì„ê³„ê°’ì˜ ì°¨ì´
                        delta_crit = test_stat - value
                        # ìƒ‰ìƒ ì„¤ì •: ADF í†µê³„ëŸ‰ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì¢‹ì€ ê²ƒì´ë¯€ë¡œ inverse ì‚¬ìš©
                        color_setting = "inverse"
                        
                        # ê° ì»¬ëŸ¼ì— ì„ê³„ê°’ ë©”íŠ¸ë¦­ ì¶”ê°€
                        if i == 0:  # 1% ì„ê³„ê°’
                            crit_col1.metric(
                                label=f"ì„ê³„ê°’ ({key})",
                                value=f"{value:.4f}",
                                delta=f"{delta_crit:.4f}",
                                delta_color=color_setting,
                                help=f"ADF í†µê³„ëŸ‰ì´ {key} ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ {key} ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒì„± ë§Œì¡±",
                                border=True
                            )
                        elif i == 1:  # 5% ì„ê³„ê°’
                            crit_col2.metric(
                                label=f"ì„ê³„ê°’ ({key})",
                                value=f"{value:.4f}",
                                delta=f"{delta_crit:.4f}",
                                delta_color=color_setting,
                                help=f"ADF í†µê³„ëŸ‰ì´ {key} ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ {key} ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒì„± ë§Œì¡±",
                                border=True
                            )
                        elif i == 2:  # 10% ì„ê³„ê°’
                            crit_col3.metric(
                                label=f"ì„ê³„ê°’ ({key})",
                                value=f"{value:.4f}",
                                delta=f"{delta_crit:.4f}",
                                delta_color=color_setting,
                                help=f"ADF í†µê³„ëŸ‰ì´ {key} ì„ê³„ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ {key} ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒì„± ë§Œì¡±",
                                border=True
                            )
                            
                # ACF, PACF ë¶„ì„
                st.markdown("---")
                st.subheader("ğŸ“Š ACF/PACF ë¶„ì„")
                
                # ACF, PACF ê³„ì‚°
                st.session_state.acf_values, st.session_state.pacf_values = cached_get_acf_pacf(st.session_state.series)
                
                acf_pacf_fig = cached_plot_acf_pacf(st.session_state.acf_values, st.session_state.pacf_values)
                st.plotly_chart(acf_pacf_fig, use_container_width=True, theme="streamlit")

                with st.expander("âœ… ìš©ì–´ ì •ë¦¬", expanded=True):
                    st.info("""
ğŸ”¹ ACF (Autocorrelation Function, ìê¸°ìƒê´€í•¨ìˆ˜)

	â€¢	í˜„ì¬ ì‹œì ì˜ ê°’ê³¼ ì´ì „ ì‹œì ë“¤ì˜ ê°’ë“¤(lag) ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì¸¡ì •
	â€¢	ì—¬ëŸ¬ ì‹œì°¨(lag)ì— ê±¸ì¹œ ì „ì²´ì ì¸ ìƒê´€ì„±ì„ íŒŒì•…í•¨
	â€¢	AR(p) ëª¨ë¸ì—ì„œ pê°’ ì¶”ì •ì— ë„ì›€

ğŸ”¹ PACF (Partial Autocorrelation Function, ë¶€ë¶„ ìê¸°ìƒê´€í•¨ìˆ˜)

	â€¢	ì¤‘ê°„ì— ë¼ì–´ ìˆëŠ” ì‹œì ë“¤ì˜ ì˜í–¥ì„ ì œê±°í•˜ê³ , ì§€ì •í•œ lagì™€ ì§ì ‘ì ì¸ ìƒê´€ë§Œ ì¶”ì •
	â€¢	ì¦‰, lag-kì™€ í˜„ì¬ ì‹œì  ì‚¬ì´ì˜ ìˆœìˆ˜í•œ ì§ì ‘ ê´€ê³„ë§Œ ë³´ëŠ” ê²ƒ
	â€¢	AR(p) ëª¨ë¸ì—ì„œ pì˜ ê²°ì •ì— ë§¤ìš° ì¤‘ìš”""")
            except Exception as e:
                st.error(f"ì •ìƒì„± ê²€ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with tab4:
            # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            st.subheader("ğŸ¤– ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡")
            
            # ì‚¬ì´ë“œë°”ì— í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ì˜µì…˜ ì¶”ê°€
            test_size = st.sidebar.slider(
                "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨",
                min_value=0.1,
                max_value=0.5,
                value=st.session_state.test_size,
                step=0.05
            )
            st.session_state.test_size = test_size
            
            # ëª¨ë¸ ì„ íƒ
            model_factory = get_model_factory()
            
            if model_factory is None:
                st.error("ëª¨ë¸ íŒ©í† ë¦¬ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                available_models = model_factory.get_all_available_models()
                
                # ëª¨ë¸ ì…€ë ‰í„° - expander ë‚´ì— ë°°ì¹˜ (ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì ‘íŒ ìƒíƒœ)
                with st.expander("ëª¨ë¸ ì„ íƒ ë° ì„¤ì •", not st.session_state.models_trained):
                    selected_models = st.multiselect(
                        "ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
                        available_models,
                        default=available_models[:] if not st.session_state.selected_models else st.session_state.selected_models
                    )
                    st.session_state.selected_models = selected_models
                    
                    # ë³µì¡ë„ ì„¤ì • ì¶”ê°€
                    complexity = st.radio(
                        "ëª¨ë¸ ë³µì¡ë„ ì„¤ì •",
                        ["ê°„ë‹¨ (ë¹ ë¦„, ì €ë©”ëª¨ë¦¬)", "ì¤‘ê°„", "ë³µì¡ (ì •í™•ë„ ë†’ìŒ, ê³ ë©”ëª¨ë¦¬)"],
                        index=0,
                        horizontal=True,
                        help="ë‚®ì€ ë³µì¡ë„ëŠ” ê³„ì‚° ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                    st.session_state.complexity = complexity
                
                # ëª¨ë¸ í•™ìŠµ ë²„íŠ¼ - í•­ìƒ í‘œì‹œ
                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button("ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘", use_container_width=True, type="primary"):
                        if not selected_models:
                            st.warning("ìµœì†Œí•œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        else:
                            with st.spinner("ëª¨ë¸ì„ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
                                train_models()
                
                with col2:
                    if st.button("ê²°ê³¼ ì´ˆê¸°í™”", use_container_width=True):
                        st.session_state.models_trained = False
                        st.session_state.forecasts = {}
                        st.session_state.metrics = {}
                        st.session_state.best_model = None
                        st.rerun()
                
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼ í‘œì‹œ (í•­ìƒ í™•ì¸í•˜ì—¬ íƒ­ ì „í™˜ í›„ì—ë„ í‘œì‹œ)
            if st.session_state.models_trained and st.session_state.forecasts:
                st.markdown("---")
                st.subheader("ğŸ“Š ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼")
                
                # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”
                comparison_fig = cached_plot_forecast_comparison(
                    st.session_state.train, 
                    st.session_state.test, 
                    st.session_state.forecasts
                )
                st.plotly_chart(comparison_fig, use_container_width=True, theme="streamlit")
                
                # ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                metrics_fig = cached_plot_metrics_comparison(st.session_state.metrics)
                st.plotly_chart(metrics_fig, use_container_width=True, theme="streamlit")
                
                # ë©”íŠ¸ë¦­ í‘œ í‘œì‹œ
                st.subheader("ğŸ“‹ ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
                metrics_df = pd.DataFrame({model: st.session_state.metrics[model] for model in st.session_state.metrics})
                st.write(metrics_df)
                
                # ìµœì  ëª¨ë¸ ì„ íƒ
                if st.session_state.best_model:
                    st.success(f"ìµœì  ëª¨ë¸ (RMSE ê¸°ì¤€): {st.session_state.best_model}")
                
                # ì„ íƒí•œ ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„
                if st.session_state.best_model in st.session_state.forecasts:
                    with st.expander("ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„", expanded=True):
                        st.subheader(f"ğŸ“ˆ ìµœì  ëª¨ë¸ ({st.session_state.best_model}) ìƒì„¸ ë¶„ì„")
                        
                        # ì”ì°¨ ë¶„ì„
                        best_forecast = st.session_state.forecasts[st.session_state.best_model]
                        residuals_fig = cached_plot_residuals(st.session_state.test, best_forecast)
                        st.plotly_chart(residuals_fig, use_container_width=True, theme="streamlit")
        with tab5:
            # LLM ë¶„ì„ íƒ­
            st.subheader("ğŸ¤– LLM ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„")
            
            with st.expander("ğŸ“Š LLM ë¶„ì„ ì„¤ì •", expanded=True):
                st.info(f"Ollama ì„œë²„ë¥¼ í†µí•´ {app_config.OLLAMA_MODEL} ëª¨ë¸ë¡œ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            def check_analysis_ready():
                """
                LLM ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì™€ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                """
                # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì™€ í‰ê°€ ì§€í‘œë¥¼ ìš°ì„  í™•ì¸
                if not hasattr(st.session_state, 'forecasts') or not st.session_state.forecasts:
                    return False, "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'metrics') or not st.session_state.metrics:
                    return False, "ëª¨ë¸ í‰ê°€ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'best_model') or st.session_state.best_model is None:
                    return False, "ìµœì  ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                
                # ì‹œê³„ì—´ ë°ì´í„°ëŠ” í•„ìˆ˜ í™•ì¸
                if not hasattr(st.session_state, 'series') or st.session_state.series is None:
                    return False, "ì‹œê³„ì—´ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                
                # train/test ë°ì´í„°ëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ì§„í–‰
                if not hasattr(st.session_state, 'train') or st.session_state.train is None or not hasattr(st.session_state, 'test') or st.session_state.test is None:
                    st.warning("í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, ëª¨ë¸ ê²°ê³¼ê°€ ìˆìœ¼ë¯€ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                
                return True, "ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ"
            
            # LLM ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
            if st.button("LLM ë¶„ì„ ì‹œì‘", type="primary"):
                
                # ë°ì´í„° ë° ëª¨ë¸ í•™ìŠµ ìƒíƒœ í™•ì¸
                is_ready, message = check_analysis_ready()
                
                if not is_ready:
                    st.warning(message)
                else:
                    with st.spinner("LLMì„ í†µí•´ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            llm_connector = LLMConnector(
                                base_url=app_config.OLLAMA_SERVER,
                                model=app_config.OLLAMA_MODEL
                            )
                            
                            # ë°ì´í„° ì •ë³´ ìˆ˜ì§‘ - ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ
                            data_info = {
                                "target_variable": st.session_state.selected_target,
                                "station": st.session_state.selected_station if hasattr(st.session_state, 'selected_station') else None,
                                "seasonality_period": st.session_state.period if hasattr(st.session_state, 'period') else None,
                                "data_range": {
                                    "total_points": len(st.session_state.series),
                                },
                                "date_range": {
                                    "start": str(st.session_state.series.index.min()),
                                    "end": str(st.session_state.series.index.max())
                                },
                                "value_stats": {
                                    "min": float(st.session_state.series.min()),
                                    "max": float(st.session_state.series.max()),
                                    "mean": float(st.session_state.series.mean()),
                                    "std": float(st.session_state.series.std())
                                }
                            }

                            # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            if hasattr(st.session_state, 'train') and st.session_state.train is not None:
                                data_info["data_range"]["train_points"] = len(st.session_state.train)

                            if hasattr(st.session_state, 'test') and st.session_state.test is not None:
                                data_info["data_range"]["test_points"] = len(st.session_state.test)
                            
                            # ì •ìƒì„± ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                            if (hasattr(st.session_state, 'stationarity_result') 
                                and st.session_state.stationarity_result is not None):
                                try:
                                    data_info["stationarity"] = {
                                        "is_stationary": bool(st.session_state.stationarity_result["is_stationary"]),
                                        "p_value": float(st.session_state.stationarity_result["p_value"]),
                                        "test_statistic": float(st.session_state.stationarity_result["test_statistic"])
                                    }
                                except (KeyError, TypeError):
                                    # ì •ìƒì„± ì •ë³´ì— í•„ìš”í•œ í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                                    pass
                            
                            # ë¶„í•´ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ, ìš”ì•½ ì •ë³´ë§Œ)
                            if (hasattr(st.session_state, 'decomposition') 
                                and st.session_state.decomposition is not None):
                                try:
                                    decomp_info = {}
                                    for comp_name, comp_data in st.session_state.decomposition.items():
                                        if comp_name != 'observed' and comp_data is not None:  # ì›ë³¸ ë°ì´í„°ëŠ” ì œì™¸
                                            clean_data = comp_data.dropna()
                                            if not clean_data.empty:
                                                decomp_info[comp_name] = {
                                                    "min": float(clean_data.min()),
                                                    "max": float(clean_data.max()),
                                                    "mean": float(clean_data.mean())
                                                }
                                    
                                    if decomp_info:  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                                        data_info["decomposition"] = decomp_info
                                except Exception as e:
                                    st.warning(f"ë¶„í•´ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œë¨): {e}")
                            
                            # ëª¨ë¸ ê²°ê³¼ ì •ë³´ ìˆ˜ì§‘
                            model_results = {
                                "best_model": st.session_state.best_model,
                                "models": {}
                            }
                            
                            # ê° ëª¨ë¸ì˜ ë©”íŠ¸ë¦­ ì •ë³´ ì¶”ê°€
                            for model_name, metrics in st.session_state.metrics.items():
                                model_results["models"][model_name] = {
                                    "metrics": {}
                                }
                                for metric_name, metric_value in metrics.items():
                                    # NaN ê°’ ì²˜ë¦¬
                                    if pd.isna(metric_value):
                                        model_results["models"][model_name]["metrics"][metric_name] = None
                                    else:
                                        model_results["models"][model_name]["metrics"][metric_name] = float(metric_value)
                                
                                # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ í†µê³„ ì¶”ê°€
                                if model_name in st.session_state.forecasts:
                                    forecast = st.session_state.forecasts[model_name]
                                    if forecast is not None and len(forecast) > 0:
                                        model_results["models"][model_name]["forecast_stats"] = {
                                            "min": float(np.min(forecast)),
                                            "max": float(np.max(forecast)),
                                            "mean": float(np.mean(forecast)),
                                            "std": float(np.std(forecast))
                                        }
                            
                            # LLM ë¶„ì„ ìš”ì²­
                            analysis_result = llm_connector.analyze_time_series(
                                data_info,
                                model_results,
                                TIME_SERIES_ANALYSIS_PROMPT
                            )
                            
                            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            st.markdown(analysis_result)
                            
                            # ì„¸ì…˜ ìƒíƒœì— ë¶„ì„ ê²°ê³¼ ì €ì¥
                            st.session_state.llm_analysis = analysis_result
                            
                            # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                            st.download_button(
                                label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                                data=analysis_result,
                                file_name="time_series_analysis_report.md",
                                mime="text/markdown"
                            )
                            
                        except Exception as e:
                            st.error(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

            # ì´ì „ì— ë¶„ì„í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            elif hasattr(st.session_state, 'llm_analysis') and st.session_state.llm_analysis:
                st.markdown(st.session_state.llm_analysis)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                    data=st.session_state.llm_analysis,
                    file_name="time_series_analysis_report.md",
                    mime="text/markdown"
                )
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ
        show_memory_usage()
    else:
        st.info("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
    

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
