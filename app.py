"""
ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„ ë©”ì¸ Streamlit ì•±
"""
import os
import warnings
from datetime import datetime, timedelta

import streamlit as st
import pandas as pd
import numpy as np

from config.settings import app_config
from utils.data_reader import get_seoul_air_quality
from utils.data_processor import DataProcessor
from utils.visualizer import TimeSeriesVisualizer
from utils.llm_connector import LLMConnector
from prompts.time_series_analysis_prompt import TIME_SERIES_ANALYSIS_PROMPT

import os
# GPU ì‚¬ìš© ë¹„í™œì„±í™” (CPU ëª¨ë“œë§Œ ì‚¬ìš©)
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
# TensorFlow ë¡œê·¸ ë ˆë²¨ ì¡°ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=app_config.APP_TITLE,
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ê°ì²´ ì´ˆê¸°í™”
data_processor = DataProcessor()
visualizer = TimeSeriesVisualizer()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'data_source' not in st.session_state:
        st.session_state.data_source = "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°"
    if 'selected_station' not in st.session_state:
        st.session_state.selected_station = None
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    if 'series' not in st.session_state:
        st.session_state.series = None
    if 'train' not in st.session_state:
        st.session_state.train = None
    if 'test' not in st.session_state:
        st.session_state.test = None
    if 'period' not in st.session_state:
        st.session_state.period = 24
    if 'decomposition' not in st.session_state:
        st.session_state.decomposition = None
    if 'stationarity_result' not in st.session_state:
        st.session_state.stationarity_result = None
    if 'acf_values' not in st.session_state:
        st.session_state.acf_values = None
    if 'pacf_values' not in st.session_state:
        st.session_state.pacf_values = None
    if 'forecasts' not in st.session_state:
        st.session_state.forecasts = {}
    if 'metrics' not in st.session_state:
        st.session_state.metrics = {}
    if 'models_trained' not in st.session_state:
        st.session_state.models_trained = False
    if 'selected_models' not in st.session_state:
        st.session_state.selected_models = []
    if 'test_size' not in st.session_state:
        st.session_state.test_size = app_config.DEFAULT_TEST_SIZE
    if 'best_model' not in st.session_state:
        st.session_state.best_model = None

# ëª¨ë¸ íŒ©í† ë¦¬ ë™ì  ë¡œë“œ
@st.cache_resource
def get_model_factory():
    """
    ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    í•„ìš”í•  ë•Œë§Œ importí•˜ì—¬ ì‹œì‘ ì‹œ pmdarima ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        from models.model_factory import ModelFactory
        return ModelFactory()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”: pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return None

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data(ttl=3600)
def load_data(file_path=None, start_date=None, end_date=None):
    """
    CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        if file_path and os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            return df
        else:
            st.info("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            
            if not start_date or not end_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ í•œ ë‹¬
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            
            df = get_seoul_air_quality(app_config.SEOUL_API_KEY, start_date, end_date)
            
            if df is not None and not df.empty:
                # íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(app_config.DATA_DIR, exist_ok=True)
                df.to_csv(app_config.DEFAULT_DATA_FILE, index=False, encoding='utf-8-sig')
                st.success(f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {app_config.DEFAULT_DATA_FILE}")
            
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì•± í—¤ë” í•¨ìˆ˜
def render_header():
    """
    ì•± í—¤ë” ë Œë”ë§
    """
    st.title("ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„")
    st.markdown("ì„œìš¸ì‹œ IoT ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹œê³„ì—´ ë¶„ì„ ì•±")
    
    # í™•ì¥ ê°€ëŠ¥í•œ ì•± ì†Œê°œ
    with st.expander("ğŸ“Œ App Introduction and Usage"):
        st.markdown("""
        ### ğŸ“Œ ì•± ì†Œê°œ
        ì´ ì•±ì€ ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

        ### ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥
        1. **ë°ì´í„° íƒìƒ‰**: ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™” ì œê³µ
        2. **ì‹œê³„ì—´ ë¶„í•´**: ì¶”ì„¸(Trend), ê³„ì ˆì„±(Seasonality), ë¶ˆê·œì¹™ì„±(Irregularity) ë¶„ì„
        3. **ëª¨ë¸ ë¹„êµ**: ARIMA/SARIMA, ì§€ìˆ˜í‰í™œë²•, Prophet, LSTM ë“± ë‹¤ì–‘í•œ ì˜ˆì¸¡ ëª¨ë¸ ì§€ì›
        4. **ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€**: RMSE, MAE, RÂ² ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê¸°ë°˜ í‰ê°€

        ### ğŸ› ï¸ ì‚¬ìš© ë°©ë²•
        1. ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” API ìˆ˜ì§‘ ì˜µì…˜ ì„ íƒ
        2. ë¶„ì„í•  ì¸¡ì •ì†Œì™€ ë³€ìˆ˜(PM10, PM25 ë“±) ì„ íƒ
        3. ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜ ì„¤ì • í›„ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        4. ê²°ê³¼ íƒ­ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
        """)

# ë°ì´í„° ì†ŒìŠ¤ ë³€ê²½ ì½œë°±
def on_data_source_change():
    st.session_state.df = None
    st.session_state.series = None
    st.session_state.train = None
    st.session_state.test = None
    st.session_state.models_trained = False

# ì¸¡ì •ì†Œ/íƒ€ê²Ÿ ë³€ê²½ ì½œë°±
def update_series():
    if st.session_state.df is not None:
        # ì„ íƒëœ ì¸¡ì •ì†Œì™€ íƒ€ê²Ÿ ë³€ìˆ˜ì— ë”°ë¼ ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬
        st.session_state.series = data_processor.preprocess_data(
            st.session_state.df, 
            st.session_state.selected_target, 
            st.session_state.selected_station
        )
        # ëª¨ë¸ í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.train = None
        st.session_state.test = None
        st.session_state.models_trained = False

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_models():
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    st.session_state.train, st.session_state.test = data_processor.train_test_split(
        st.session_state.series, 
        st.session_state.test_size
    )
    
    # ëª¨ë¸ íŒ©í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    model_factory = get_model_factory()
    
    if model_factory is None:
        st.error("ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.error("ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
    forecasts = {}
    metrics = {}
    
    # ëª¨ë¸ ê°œìˆ˜
    total_models = len(st.session_state.selected_models)
    completed_models = 0
    
    # ê° ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    for model_type in st.session_state.selected_models:
        status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            model = model_factory.get_model(model_type)
            
            # ëª¨ë¸ë³„ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
            if model_type == 'arima':
                # ARIMA ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal=True,
                    m=st.session_state.period
                )
            elif model_type == 'exp_smoothing':
                # ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal_periods=st.session_state.period
                )
            elif model_type == 'prophet':
                # Prophet ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    daily_seasonality=True,
                    weekly_seasonality=True
                )
            elif model_type == 'lstm':
                # LSTM ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    n_steps=min(48, len(st.session_state.train) // 10),  # ì‹œí€€ìŠ¤ ê¸¸ì´
                    lstm_units=[50, 50],
                    dropout_rate=0.2,
                    epochs=100,
                    batch_size=32,
                    validation_split=0.1
                )
            else:
                # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test
                )
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
            forecasts[model.name] = forecast
            metrics[model.name] = model_metrics
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            completed_models += 1
            progress_bar.progress(completed_models / total_models)
            
        except Exception as e:
            st.error(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥
    if forecasts:
        st.session_state.forecasts = forecasts
        st.session_state.metrics = metrics
        st.session_state.models_trained = True
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        rmse_values = {model: metrics[model]['RMSE'] for model in metrics}
        st.session_state.best_model = min(rmse_values.items(), key=lambda x: x[1])[0]
        
        status_text.text("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    else:
        st.error("ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í•¨ìˆ˜
def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì•± í—¤ë” ë Œë”ë§
    render_header()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š ë¶„ì„ ì„¤ì •")

    st.sidebar.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    st.sidebar.subheader("ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„° ë¡œë“œ", help="ì„œìš¸ì‹œ IoT ëŒ€ê¸°ì§ˆ ë°ì´í„° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.")


    # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
    today = datetime.now().date()  # datetime.date ê°ì²´ë¡œ ë³€í™˜
    default_end_date = today
    default_start_date = today - timedelta(days=30)

    st.sidebar.markdown("##### ğŸ“… ë¶„ì„ ê¸°ê°„ ì„ íƒ", help="ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”. (ìµœëŒ€ 30ì¼)")

    date_col1, date_col2 = st.sidebar.columns(2)

    with date_col1:
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            default_start_date
        )
        
    with date_col2:
        # ì‹œì‘ì¼ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ì¢…ë£Œì¼ ê³„ì‚° (30ì¼ ì´ë‚´)
        max_end_date = start_date + timedelta(days=30)
        if today < max_end_date:
            max_end_date = today
            
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            min(default_end_date, max_end_date),
            min_value=start_date,
            max_value=max_end_date
        )

    # ì„ íƒëœ ë‚ ì§œ ë²”ìœ„ ì¼ìˆ˜ ê³„ì‚°
    date_range_days = (end_date - start_date).days

    # ê¸°ê°„ í‘œì‹œ ì •ë³´ ë° ì‹œê°í™”
    progress_value = min(date_range_days / 30, 1.0)
    st.sidebar.progress(progress_value)
    st.sidebar.text(f"ì„ íƒëœ ê¸°ê°„: {date_range_days + 1}ì¼ / ìµœëŒ€ 30ì¼")

    if date_range_days > 25:
        st.sidebar.warning("ë°ì´í„° ì–‘ì´ ë§ì„ìˆ˜ë¡ ë¶„ì„ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼
    if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        with st.spinner("ì„œìš¸ì‹œ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            df = load_data(
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d")
            )
            if df is not None and not df.empty:
                st.session_state.df = df

    st.sidebar.markdown("---")
    
    # ë°ì´í„°ê°€ ë¡œë“œë˜ë©´ ë¶„ì„ ì‹œì‘
    if st.session_state.df is not None and not st.session_state.df.empty:
        # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            st.write(st.session_state.df.head())
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ë°ì´í„° í¬ê¸°:** {st.session_state.df.shape[0]} í–‰ Ã— {st.session_state.df.shape[1]} ì—´")
                st.write(f"**ê¸°ê°„:** {st.session_state.df['MSRDT'].min()} ~ {st.session_state.df['MSRDT'].max()}")
            
            with col2:
                if 'MSRSTE_NM' in st.session_state.df.columns:
                    st.write(f"**ì¸¡ì •ì†Œ ìˆ˜:** {st.session_state.df['MSRSTE_NM'].nunique()}ê°œ")
                    st.write(f"**ì¸¡ì •ì†Œ ëª©ë¡:** {', '.join(sorted(st.session_state.df['MSRSTE_NM'].unique()))}")
        
        # ë¶„ì„ ì˜µì…˜ ì„¤ì •
        st.sidebar.subheader("ğŸ” ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜")
        
        # ì¸¡ì •ì†Œ ì„ íƒ
        if 'MSRSTE_NM' in st.session_state.df.columns:
            stations = ['ì „ì²´ í‰ê· '] + sorted(st.session_state.df['MSRSTE_NM'].unique().tolist())
            selected_station = st.sidebar.selectbox(
                "Select Station", 
                stations,
                index=0 if st.session_state.selected_station is None else stations.index(st.session_state.selected_station if st.session_state.selected_station else "ì „ì²´ í‰ê· ")
            )
            
            if selected_station == 'ì „ì²´ í‰ê· ':
                st.session_state.selected_station = None
            else:
                st.session_state.selected_station = selected_station
        else:
            st.session_state.selected_station = None
            st.sidebar.info("ì¸¡ì •ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        numeric_columns = st.session_state.df.select_dtypes(include=np.number).columns.tolist()
        target_options = [col for col in numeric_columns if col in ['PM10', 'PM25', 'O3', 'NO2', 'CO', 'SO2']]
        
        if not target_options:
            target_options = numeric_columns
        
        if target_options:
            selected_target = st.sidebar.selectbox(
                "ë¶„ì„í•  ë³€ìˆ˜ ì„ íƒ", 
                target_options,
                index=0 if st.session_state.selected_target is None else target_options.index(st.session_state.selected_target)
            )
            st.session_state.selected_target = selected_target
        else:
            st.error("ë¶„ì„ ê°€ëŠ¥í•œ ìˆ«ìí˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì‹œë¦¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸
        update_series()
        
        # ì‹œê³„ì—´ ë¶„ì„ íƒ­
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ì‹œê³„ì—´ ì‹œê°í™”", 
            "ì‹œê³„ì—´ ë¶„í•´", 
            "ì •ìƒì„± & ACF/PACF", 
            "ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡",
            "LLM ë¶„ì„"
        ])
        
        with tab1:
            # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
            st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ì‹œê°í™”")
            
            # ì„ íƒí•œ ì¸¡ì •ì†Œì™€ ë³€ìˆ˜ì— ëŒ€í•œ ì‹œê³„ì—´ ê·¸ë˜í”„
            station_text = f"{st.session_state.selected_station} " if st.session_state.selected_station else "Seoul City Overall "
            fig = visualizer.plot_timeseries(
                st.session_state.series,
                title=f"{station_text}{st.session_state.selected_target} Time Series Data",
                ylabel=st.session_state.selected_target
            )
            st.pyplot(fig)
        
        with tab2:
            # ì‹œê³„ì—´ ë¶„í•´
            st.subheader("ğŸ”„ ì‹œê³„ì—´ ë¶„í•´", help="ì‹œê³„ì—´ ë¶„í•´(Time Series Decomposition)ë€, **ì‹œê³„ì—´ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ëŠ” ì—¬ëŸ¬ ìš”ì†Œ(ì„±ë¶„)**ë¥¼ ë¶„ë¦¬í•´ë‚´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ë” ì˜ ì´í•´í•˜ê³ , ì˜ˆì¸¡ë ¥ ë†’ì€ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ê³„ì ˆì„± ì£¼ê¸° ì„ íƒ
            min_period = 2
            max_period = min(len(st.session_state.series) // 2, 168)  # ìµœëŒ€ ì¼ì£¼ì¼(168ì‹œê°„) ë˜ëŠ” ë°ì´í„° ê¸¸ì´ì˜ ì ˆë°˜
            
            period = st.slider(
                "ê³„ì ˆì„± ì£¼ê¸° (ì‹œê°„ ë‹¨ìœ„)",
                min_value=min_period,
                max_value=max_period,
                value=st.session_state.period,
                help="ê³„ì ˆì„± ì£¼ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì˜ˆ: 24ì‹œê°„ì€ í•˜ë£¨ ì£¼ê¸°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
            )
            st.session_state.period = period
            
            try:
                # ì‹œê³„ì—´ ë¶„í•´ ìˆ˜í–‰
                st.session_state.decomposition = data_processor.decompose_timeseries(st.session_state.series, period)
                
                # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
                decomp_fig = visualizer.plot_decomposition(st.session_state.decomposition)
                st.pyplot(decomp_fig)
            except Exception as e:
                st.error(f"ì‹œê³„ì—´ ë¶„í•´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with tab3:
            # ì •ìƒì„± ê²€ì •
            st.subheader("ğŸ” ì •ìƒì„± ê²€ì •", help="ì •ìƒì„± ê²€ì •(Stationarity Test)ì´ë€ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì‹œê°„ì´ ì§€ë‚˜ë„ í†µê³„ì  íŠ¹ì„±ì´ ì¼ì •í•œì§€(=ì •ìƒì¸ì§€) í™•ì¸í•˜ëŠ” ê²€ì •ì…ë‹ˆë‹¤. ì¦‰, í‰ê· , ë¶„ì‚°, ìê¸°ê³µë¶„ì‚° ë“±ì˜ ê°’ì´ ì‹œê°„ì— ë”°ë¼ ë³€í•˜ì§€ ì•ŠëŠ”ì§€ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤")
            
            try:
                # ì •ìƒì„± ê²€ì • ìˆ˜í–‰
                st.session_state.stationarity_result = data_processor.check_stationarity(st.session_state.series)
                
                # ì •ìƒì„± ê²€ì • ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ADF í†µê³„ëŸ‰:** {st.session_state.stationarity_result['test_statistic']:.4f}")
                    st.write(f"**p-ê°’:** {st.session_state.stationarity_result['p_value']:.4f}")
                    
                    # ì •ìƒì„± ì—¬ë¶€
                    if st.session_state.stationarity_result['is_stationary']:
                        st.success("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
                    else:
                        st.warning("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                with col2:
                    st.write("**ì„ê³„ê°’:**")
                    for key, value in st.session_state.stationarity_result['critical_values'].items():
                        st.write(f"{key}: {value:.4f}")
                
                # ACF, PACF ë¶„ì„
                st.subheader("ğŸ“Š ACF/PACF ë¶„ì„")
                
                # ACF, PACF ê³„ì‚°
                st.session_state.acf_values, st.session_state.pacf_values = data_processor.get_acf_pacf(st.session_state.series)
                
                acf_pacf_fig = visualizer.plot_acf_pacf(st.session_state.acf_values, st.session_state.pacf_values)
                st.pyplot(acf_pacf_fig)
            except Exception as e:
                st.error(f"ì •ìƒì„± ê²€ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with tab4:
            # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            st.subheader("ğŸ¤– ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡")
            
            # ì‚¬ì´ë“œë°”ì— í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ì˜µì…˜ ì¶”ê°€
            test_size = st.sidebar.slider(
                "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨",
                min_value=0.1,
                max_value=0.5,
                value=st.session_state.test_size,
                step=0.05
            )
            st.session_state.test_size = test_size
            
            # ëª¨ë¸ ì„ íƒ
            model_factory = get_model_factory()
            
            if model_factory is None:
                st.error("ëª¨ë¸ íŒ©í† ë¦¬ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                available_models = model_factory.get_all_available_models()
                
                selected_models = st.sidebar.multiselect(
                    "ëª¨ë¸ ì„ íƒ",
                    available_models,
                    default=available_models[:] if not st.session_state.selected_models else st.session_state.selected_models
                )
                st.session_state.selected_models = selected_models
                
                # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ë²„íŠ¼
                if st.button("ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘"):
                    if not selected_models:
                        st.warning("ìµœì†Œí•œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("ëª¨ë¸ì„ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
                            train_models()
            
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼ í‘œì‹œ
            if st.session_state.models_trained and st.session_state.forecasts:
                # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“Š ì˜ˆì¸¡ ë¹„êµ")
                comparison_fig = visualizer.plot_forecast_comparison(
                    st.session_state.train, 
                    st.session_state.test, 
                    st.session_state.forecasts
                )
                st.pyplot(comparison_fig)
                
                # ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                metrics_fig = visualizer.plot_metrics_comparison(st.session_state.metrics)
                st.pyplot(metrics_fig)
                
                # ë©”íŠ¸ë¦­ í‘œ í‘œì‹œ
                st.subheader("ğŸ“‹ ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
                metrics_df = pd.DataFrame({model: st.session_state.metrics[model] for model in st.session_state.metrics})
                st.write(metrics_df)
                
                # ìµœì  ëª¨ë¸ ì„ íƒ
                if st.session_state.best_model:
                    st.success(f"ìµœì  ëª¨ë¸ (RMSE ê¸°ì¤€): {st.session_state.best_model}")
                
                # ì„ íƒí•œ ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„
                if st.session_state.best_model in st.session_state.forecasts:
                    st.subheader(f"ğŸ“ˆ ìµœì  ëª¨ë¸ ({st.session_state.best_model}) ìƒì„¸ ë¶„ì„")
                    
                    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
                    best_forecast = st.session_state.forecasts[st.session_state.best_model]
                    
                    # ì”ì°¨ ë¶„ì„
                    residuals_fig = visualizer.plot_residuals(st.session_state.test, best_forecast)
                    st.pyplot(residuals_fig)
        with tab5:
            # LLM ë¶„ì„ íƒ­
            st.subheader("ğŸ¤– LLM ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„")
            
            with st.expander("ğŸ“Š LLM ë¶„ì„ ì„¤ì •", expanded=True):
                st.info(f"Ollama ì„œë²„ë¥¼ í†µí•´ {app_config.OLLAMA_MODEL} ëª¨ë¸ë¡œ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            def check_analysis_ready():
                """
                LLM ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì™€ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                """
                # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì™€ í‰ê°€ ì§€í‘œë¥¼ ìš°ì„  í™•ì¸
                if not hasattr(st.session_state, 'forecasts') or not st.session_state.forecasts:
                    return False, "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'metrics') or not st.session_state.metrics:
                    return False, "ëª¨ë¸ í‰ê°€ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                    
                if not hasattr(st.session_state, 'best_model') or st.session_state.best_model is None:
                    return False, "ìµœì  ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡' íƒ­ì—ì„œ ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                
                # ì‹œê³„ì—´ ë°ì´í„°ëŠ” í•„ìˆ˜ í™•ì¸
                if not hasattr(st.session_state, 'series') or st.session_state.series is None:
                    return False, "ì‹œê³„ì—´ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                
                # train/test ë°ì´í„°ëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ì§„í–‰
                if not hasattr(st.session_state, 'train') or st.session_state.train is None or not hasattr(st.session_state, 'test') or st.session_state.test is None:
                    st.warning("í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, ëª¨ë¸ ê²°ê³¼ê°€ ìˆìœ¼ë¯€ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                
                return True, "ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ"
            
            # LLM ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
            if st.button("LLM ë¶„ì„ ì‹œì‘", type="primary"):
                
                # ë°ì´í„° ë° ëª¨ë¸ í•™ìŠµ ìƒíƒœ í™•ì¸
                is_ready, message = check_analysis_ready()
                
                if not is_ready:
                    st.warning(message)
                else:
                    with st.spinner("LLMì„ í†µí•´ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            llm_connector = LLMConnector(
                                base_url=app_config.OLLAMA_SERVER,
                                model=app_config.OLLAMA_MODEL
                            )
                            
                            # ë°ì´í„° ì •ë³´ ìˆ˜ì§‘ - ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ
                            data_info = {
                                "target_variable": st.session_state.selected_target,
                                "station": st.session_state.selected_station if hasattr(st.session_state, 'selected_station') else None,
                                "seasonality_period": st.session_state.period if hasattr(st.session_state, 'period') else None,
                                "data_range": {
                                    "total_points": len(st.session_state.series),
                                },
                                "date_range": {
                                    "start": str(st.session_state.series.index.min()),
                                    "end": str(st.session_state.series.index.max())
                                },
                                "value_stats": {
                                    "min": float(st.session_state.series.min()),
                                    "max": float(st.session_state.series.max()),
                                    "mean": float(st.session_state.series.mean()),
                                    "std": float(st.session_state.series.std())
                                }
                            }

                            # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            if hasattr(st.session_state, 'train') and st.session_state.train is not None:
                                data_info["data_range"]["train_points"] = len(st.session_state.train)

                            if hasattr(st.session_state, 'test') and st.session_state.test is not None:
                                data_info["data_range"]["test_points"] = len(st.session_state.test)
                            
                            # ì •ìƒì„± ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                            if (hasattr(st.session_state, 'stationarity_result') 
                                and st.session_state.stationarity_result is not None):
                                try:
                                    data_info["stationarity"] = {
                                        "is_stationary": bool(st.session_state.stationarity_result["is_stationary"]),
                                        "p_value": float(st.session_state.stationarity_result["p_value"]),
                                        "test_statistic": float(st.session_state.stationarity_result["test_statistic"])
                                    }
                                except (KeyError, TypeError):
                                    # ì •ìƒì„± ì •ë³´ì— í•„ìš”í•œ í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                                    pass
                            
                            # ë¶„í•´ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ, ìš”ì•½ ì •ë³´ë§Œ)
                            if (hasattr(st.session_state, 'decomposition') 
                                and st.session_state.decomposition is not None):
                                try:
                                    decomp_info = {}
                                    for comp_name, comp_data in st.session_state.decomposition.items():
                                        if comp_name != 'observed' and comp_data is not None:  # ì›ë³¸ ë°ì´í„°ëŠ” ì œì™¸
                                            clean_data = comp_data.dropna()
                                            if not clean_data.empty:
                                                decomp_info[comp_name] = {
                                                    "min": float(clean_data.min()),
                                                    "max": float(clean_data.max()),
                                                    "mean": float(clean_data.mean())
                                                }
                                    
                                    if decomp_info:  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                                        data_info["decomposition"] = decomp_info
                                except Exception as e:
                                    st.warning(f"ë¶„í•´ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œë¨): {e}")
                            
                            # ëª¨ë¸ ê²°ê³¼ ì •ë³´ ìˆ˜ì§‘
                            model_results = {
                                "best_model": st.session_state.best_model,
                                "models": {}
                            }
                            
                            # ê° ëª¨ë¸ì˜ ë©”íŠ¸ë¦­ ì •ë³´ ì¶”ê°€
                            for model_name, metrics in st.session_state.metrics.items():
                                model_results["models"][model_name] = {
                                    "metrics": {}
                                }
                                for metric_name, metric_value in metrics.items():
                                    # NaN ê°’ ì²˜ë¦¬
                                    if pd.isna(metric_value):
                                        model_results["models"][model_name]["metrics"][metric_name] = None
                                    else:
                                        model_results["models"][model_name]["metrics"][metric_name] = float(metric_value)
                                
                                # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ í†µê³„ ì¶”ê°€
                                if model_name in st.session_state.forecasts:
                                    forecast = st.session_state.forecasts[model_name]
                                    if forecast is not None and len(forecast) > 0:
                                        model_results["models"][model_name]["forecast_stats"] = {
                                            "min": float(np.min(forecast)),
                                            "max": float(np.max(forecast)),
                                            "mean": float(np.mean(forecast)),
                                            "std": float(np.std(forecast))
                                        }
                            
                            # LLM ë¶„ì„ ìš”ì²­
                            analysis_result = llm_connector.analyze_time_series(
                                data_info,
                                model_results,
                                TIME_SERIES_ANALYSIS_PROMPT
                            )
                            
                            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            st.markdown(analysis_result)
                            
                            # ì„¸ì…˜ ìƒíƒœì— ë¶„ì„ ê²°ê³¼ ì €ì¥
                            st.session_state.llm_analysis = analysis_result
                            
                            # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                            st.download_button(
                                label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                                data=analysis_result,
                                file_name="time_series_analysis_report.md",
                                mime="text/markdown"
                            )
                            
                        except Exception as e:
                            st.error(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

            # ì´ì „ì— ë¶„ì„í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            elif hasattr(st.session_state, 'llm_analysis') and st.session_state.llm_analysis:
                st.markdown(st.session_state.llm_analysis)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                    data=st.session_state.llm_analysis,
                    file_name="time_series_analysis_report.md",
                    mime="text/markdown"
                )
    else:
        st.info("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
