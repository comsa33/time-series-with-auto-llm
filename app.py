"""
ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„ ë©”ì¸ Streamlit ì•±
"""
import os
import warnings
from datetime import datetime, timedelta

import streamlit as st
import pandas as pd
import numpy as np

from config.settings import app_config
from utils.data_reader import get_seoul_air_quality
from utils.data_processor import DataProcessor
from utils.visualizer import TimeSeriesVisualizer

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=app_config.APP_TITLE,
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê°ì²´ ì´ˆê¸°í™”
data_processor = DataProcessor()
visualizer = TimeSeriesVisualizer()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'data_source' not in st.session_state:
        st.session_state.data_source = "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°"
    if 'selected_station' not in st.session_state:
        st.session_state.selected_station = None
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    if 'series' not in st.session_state:
        st.session_state.series = None
    if 'train' not in st.session_state:
        st.session_state.train = None
    if 'test' not in st.session_state:
        st.session_state.test = None
    if 'period' not in st.session_state:
        st.session_state.period = 24
    if 'decomposition' not in st.session_state:
        st.session_state.decomposition = None
    if 'stationarity_result' not in st.session_state:
        st.session_state.stationarity_result = None
    if 'acf_values' not in st.session_state:
        st.session_state.acf_values = None
    if 'pacf_values' not in st.session_state:
        st.session_state.pacf_values = None
    if 'forecasts' not in st.session_state:
        st.session_state.forecasts = {}
    if 'metrics' not in st.session_state:
        st.session_state.metrics = {}
    if 'models_trained' not in st.session_state:
        st.session_state.models_trained = False
    if 'selected_models' not in st.session_state:
        st.session_state.selected_models = []
    if 'test_size' not in st.session_state:
        st.session_state.test_size = app_config.DEFAULT_TEST_SIZE
    if 'best_model' not in st.session_state:
        st.session_state.best_model = None

# ëª¨ë¸ íŒ©í† ë¦¬ ë™ì  ë¡œë“œ
@st.cache_resource
def get_model_factory():
    """
    ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    í•„ìš”í•  ë•Œë§Œ importí•˜ì—¬ ì‹œì‘ ì‹œ pmdarima ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        from models.model_factory import ModelFactory
        return ModelFactory()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”: pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return None

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data
def load_data(file_path=None, start_date=None, end_date=None):
    """
    CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        if file_path and os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            return df
        else:
            st.info("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            
            if not start_date or not end_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ í•œ ë‹¬
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            
            df = get_seoul_air_quality(app_config.SEOUL_API_KEY, start_date, end_date)
            
            if df is not None and not df.empty:
                # íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(app_config.DATA_DIR, exist_ok=True)
                df.to_csv(app_config.DEFAULT_DATA_FILE, index=False, encoding='utf-8-sig')
                st.success(f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {app_config.DEFAULT_DATA_FILE}")
            
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì•± í—¤ë” í•¨ìˆ˜
def render_header():
    """
    ì•± í—¤ë” ë Œë”ë§
    """
    st.title("Air Quality Time Series Analysis")
    st.markdown("Seoul City IoT Data Time Series Analysis App")
    
    # í™•ì¥ ê°€ëŠ¥í•œ ì•± ì†Œê°œ
    with st.expander("ğŸ“Œ App Introduction and Usage"):
        st.markdown("""
        ### App Introduction
        This app analyzes and visualizes time series data from Seoul City's air quality data.
        
        ### Main Features
        1. **Data Exploration**: Basic statistics and visualization of Seoul's air quality data
        2. **Time Series Decomposition**: Trend, seasonality, and irregularity analysis
        3. **Model Comparison**: Various prediction models including ARIMA/SARIMA, Exponential Smoothing, Prophet, LSTM, etc.
        4. **Prediction Performance Evaluation**: Various metrics-based evaluation (RMSE, MAE, R^2, etc.)
        
        ### How to Use
        1. Select data upload or API collection options in the sidebar
        2. Choose the measurement station and variable (PM10, PM25, etc.) to analyze
        3. Set time series analysis options and run model training
        4. Compare and analyze prediction results of various models in the results tab
        """)

# ë°ì´í„° ì†ŒìŠ¤ ë³€ê²½ ì½œë°±
def on_data_source_change():
    st.session_state.df = None
    st.session_state.series = None
    st.session_state.train = None
    st.session_state.test = None
    st.session_state.models_trained = False

# ì¸¡ì •ì†Œ/íƒ€ê²Ÿ ë³€ê²½ ì½œë°±
def update_series():
    if st.session_state.df is not None:
        # ì„ íƒëœ ì¸¡ì •ì†Œì™€ íƒ€ê²Ÿ ë³€ìˆ˜ì— ë”°ë¼ ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬
        st.session_state.series = data_processor.preprocess_data(
            st.session_state.df, 
            st.session_state.selected_target, 
            st.session_state.selected_station
        )
        # ëª¨ë¸ í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.train = None
        st.session_state.test = None
        st.session_state.models_trained = False

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_models():
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    st.session_state.train, st.session_state.test = data_processor.train_test_split(
        st.session_state.series, 
        st.session_state.test_size
    )
    
    # ëª¨ë¸ íŒ©í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    model_factory = get_model_factory()
    
    if model_factory is None:
        st.error("ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.error("ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
    forecasts = {}
    metrics = {}
    
    # ëª¨ë¸ ê°œìˆ˜
    total_models = len(st.session_state.selected_models)
    completed_models = 0
    
    # ê° ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    for model_type in st.session_state.selected_models:
        status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        try:
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            model = model_factory.get_model(model_type)
            
            # ëª¨ë¸ë³„ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
            if model_type == 'arima':
                # ARIMA ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal=True,
                    m=st.session_state.period
                )
            elif model_type == 'exp_smoothing':
                # ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    seasonal_periods=st.session_state.period
                )
            elif model_type == 'prophet':
                # Prophet ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    daily_seasonality=True,
                    weekly_seasonality=True
                )
            elif model_type == 'lstm':
                # LSTM ëª¨ë¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test,
                    n_steps=min(48, len(st.session_state.train) // 10),  # ì‹œí€€ìŠ¤ ê¸¸ì´
                    lstm_units=[50, 50],
                    dropout_rate=0.2,
                    epochs=100,
                    batch_size=32,
                    validation_split=0.1
                )
            else:
                # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
                forecast, model_metrics = model.fit_predict_evaluate(
                    st.session_state.train, 
                    st.session_state.test
                )
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
            forecasts[model.name] = forecast
            metrics[model.name] = model_metrics
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            completed_models += 1
            progress_bar.progress(completed_models / total_models)
            
        except Exception as e:
            st.error(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥
    if forecasts:
        st.session_state.forecasts = forecasts
        st.session_state.metrics = metrics
        st.session_state.models_trained = True
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        rmse_values = {model: metrics[model]['RMSE'] for model in metrics}
        st.session_state.best_model = min(rmse_values.items(), key=lambda x: x[1])[0]
        
        status_text.text("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    else:
        st.error("ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í•¨ìˆ˜
def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì•± í—¤ë” ë Œë”ë§
    render_header()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š Analysis Settings")
    
    # ë°ì´í„° ë¡œë“œ ë°©ì‹ ì„ íƒ
    data_source = st.sidebar.radio(
        "Select Data Source",
        ["APIì—ì„œ ê°€ì ¸ì˜¤ê¸°", "íŒŒì¼ ì—…ë¡œë“œ"],
        key="data_source",
        on_change=on_data_source_change
    )
    
    # ë°ì´í„° ë¡œë“œ
    if data_source == "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°":
        st.sidebar.subheader("API Settings")
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        today = datetime.now()
        default_end_date = today.strftime("%Y-%m-%d")
        default_start_date = (today - timedelta(days=30)).strftime("%Y-%m-%d")
        
        start_date = st.sidebar.date_input(
            "Start Date",
            datetime.strptime(default_start_date, "%Y-%m-%d")
        )
        
        end_date = st.sidebar.date_input(
            "End Date",
            datetime.strptime(default_end_date, "%Y-%m-%d")
        )
        
        if st.sidebar.button("Get Data"):
            with st.spinner("Getting data from Seoul City API..."):
                df = load_data(
                    start_date=start_date.strftime("%Y-%m-%d"),
                    end_date=end_date.strftime("%Y-%m-%d")
                )
                if df is not None and not df.empty:
                    st.session_state.df = df
    else:
        st.sidebar.subheader("File Upload")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.sidebar.file_uploader("Upload CSV File", type=["csv"])
        
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            st.session_state.df = df
        else:
            # ê¸°ì¡´ íŒŒì¼ ì‚¬ìš©
            if os.path.exists(app_config.DEFAULT_DATA_FILE):
                use_existing = st.sidebar.checkbox("Use Existing Data", value=True)
                if use_existing:
                    df = load_data(file_path=app_config.DEFAULT_DATA_FILE)
                    if df is not None and not df.empty:
                        st.session_state.df = df
            else:
                st.sidebar.warning("No saved data file found. Please upload a file or get data from API.")
    
    # ë°ì´í„°ê°€ ë¡œë“œë˜ë©´ ë¶„ì„ ì‹œì‘
    if st.session_state.df is not None and not st.session_state.df.empty:
        # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“‹ Data Preview", expanded=True):
            st.write(st.session_state.df.head())
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Data Size:** {st.session_state.df.shape[0]} rows Ã— {st.session_state.df.shape[1]} columns")
                st.write(f"**Period:** {st.session_state.df['MSRDT'].min()} ~ {st.session_state.df['MSRDT'].max()}")
            
            with col2:
                if 'MSRSTE_NM' in st.session_state.df.columns:
                    st.write(f"**Number of Stations:** {st.session_state.df['MSRSTE_NM'].nunique()}")
                    st.write(f"**Station List:** {', '.join(sorted(st.session_state.df['MSRSTE_NM'].unique()))}")
        
        # ë¶„ì„ ì˜µì…˜ ì„¤ì •
        st.sidebar.subheader("ğŸ” Analysis Options")
        
        # ì¸¡ì •ì†Œ ì„ íƒ
        if 'MSRSTE_NM' in st.session_state.df.columns:
            stations = ['ì „ì²´ í‰ê· '] + sorted(st.session_state.df['MSRSTE_NM'].unique().tolist())
            selected_station = st.sidebar.selectbox(
                "Select Station", 
                stations,
                index=0 if st.session_state.selected_station is None else stations.index(st.session_state.selected_station if st.session_state.selected_station else "ì „ì²´ í‰ê· ")
            )
            
            if selected_station == 'ì „ì²´ í‰ê· ':
                st.session_state.selected_station = None
            else:
                st.session_state.selected_station = selected_station
        else:
            st.session_state.selected_station = None
            st.sidebar.info("No station information available.")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        numeric_columns = st.session_state.df.select_dtypes(include=np.number).columns.tolist()
        target_options = [col for col in numeric_columns if col in ['PM10', 'PM25', 'O3', 'NO2', 'CO', 'SO2']]
        
        if not target_options:
            target_options = numeric_columns
        
        if target_options:
            selected_target = st.sidebar.selectbox(
                "Select Variable", 
                target_options,
                index=0 if st.session_state.selected_target is None else target_options.index(st.session_state.selected_target)
            )
            st.session_state.selected_target = selected_target
        else:
            st.error("No numeric variables available for analysis.")
            return
        
        # ì‹œë¦¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸
        update_series()
        
        # ì‹œê³„ì—´ ë¶„ì„ íƒ­
        tab1, tab2, tab3, tab4 = st.tabs(["Time Series Visualization", "Time Series Decomposition", "Stationarity & ACF/PACF", "Model Training & Prediction"])
        
        with tab1:
            # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
            st.subheader("ğŸ“ˆ Time Series Visualization")
            
            # ì„ íƒí•œ ì¸¡ì •ì†Œì™€ ë³€ìˆ˜ì— ëŒ€í•œ ì‹œê³„ì—´ ê·¸ë˜í”„
            station_text = f"{st.session_state.selected_station} " if st.session_state.selected_station else "Seoul City Overall "
            fig = visualizer.plot_timeseries(
                st.session_state.series,
                title=f"{station_text}{st.session_state.selected_target} Time Series Data",
                ylabel=st.session_state.selected_target
            )
            st.pyplot(fig)
        
        with tab2:
            # ì‹œê³„ì—´ ë¶„í•´
            st.subheader("ğŸ”„ Time Series Decomposition")
            
            # ê³„ì ˆì„± ì£¼ê¸° ì„ íƒ
            min_period = 2
            max_period = min(len(st.session_state.series) // 2, 168)  # ìµœëŒ€ ì¼ì£¼ì¼(168ì‹œê°„) ë˜ëŠ” ë°ì´í„° ê¸¸ì´ì˜ ì ˆë°˜
            
            period = st.slider(
                "Seasonality Period (hours)",
                min_value=min_period,
                max_value=max_period,
                value=st.session_state.period
            )
            st.session_state.period = period
            
            try:
                # ì‹œê³„ì—´ ë¶„í•´ ìˆ˜í–‰
                st.session_state.decomposition = data_processor.decompose_timeseries(st.session_state.series, period)
                
                # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
                decomp_fig = visualizer.plot_decomposition(st.session_state.decomposition)
                st.pyplot(decomp_fig)
            except Exception as e:
                st.error(f"Error in time series decomposition: {str(e)}")
        
        with tab3:
            # ì •ìƒì„± ê²€ì •
            st.subheader("ğŸ” Stationarity Test")
            
            try:
                # ì •ìƒì„± ê²€ì • ìˆ˜í–‰
                st.session_state.stationarity_result = data_processor.check_stationarity(st.session_state.series)
                
                # ì •ìƒì„± ê²€ì • ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**ADF Statistic:** {st.session_state.stationarity_result['test_statistic']:.4f}")
                    st.write(f"**p-value:** {st.session_state.stationarity_result['p_value']:.4f}")
                    
                    # ì •ìƒì„± ì—¬ë¶€
                    if st.session_state.stationarity_result['is_stationary']:
                        st.success("The time series data is stationary.")
                    else:
                        st.warning("The time series data is not stationary.")
                
                with col2:
                    st.write("**Critical Values:**")
                    for key, value in st.session_state.stationarity_result['critical_values'].items():
                        st.write(f"{key}: {value:.4f}")
                
                # ACF, PACF ë¶„ì„
                st.subheader("ğŸ“Š ACF/PACF Analysis")
                
                # ACF, PACF ê³„ì‚°
                st.session_state.acf_values, st.session_state.pacf_values = data_processor.get_acf_pacf(st.session_state.series)
                
                acf_pacf_fig = visualizer.plot_acf_pacf(st.session_state.acf_values, st.session_state.pacf_values)
                st.pyplot(acf_pacf_fig)
            except Exception as e:
                st.error(f"Error in stationarity test: {str(e)}")
        
        with tab4:
            # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            st.subheader("ğŸ¤– Model Training & Prediction")
            
            # ì‚¬ì´ë“œë°”ì— í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ì˜µì…˜ ì¶”ê°€
            test_size = st.sidebar.slider(
                "Test Data Ratio",
                min_value=0.1,
                max_value=0.5,
                value=st.session_state.test_size,
                step=0.05
            )
            st.session_state.test_size = test_size
            
            # ëª¨ë¸ ì„ íƒ
            model_factory = get_model_factory()
            
            if model_factory is None:
                st.error("Model factory loading failed. May be pmdarima compatibility issue.")
                st.error("Try running the following command:")
                st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
            else:
                available_models = model_factory.get_all_available_models()
                
                selected_models = st.sidebar.multiselect(
                    "Select Models",
                    available_models,
                    default=available_models[:2] if not st.session_state.selected_models else st.session_state.selected_models
                )
                st.session_state.selected_models = selected_models
                
                # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ë²„íŠ¼
                if st.button("Start Model Training & Prediction"):
                    if not selected_models:
                        st.warning("Please select at least one model.")
                    else:
                        with st.spinner("Training models..."):
                            train_models()
            
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼ í‘œì‹œ
            if st.session_state.models_trained and st.session_state.forecasts:
                # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“Š Forecast Comparison")
                comparison_fig = visualizer.plot_forecast_comparison(
                    st.session_state.train, 
                    st.session_state.test, 
                    st.session_state.forecasts
                )
                st.pyplot(comparison_fig)
                
                # ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“ˆ Model Performance Comparison")
                metrics_fig = visualizer.plot_metrics_comparison(st.session_state.metrics)
                st.pyplot(metrics_fig)
                
                # ë©”íŠ¸ë¦­ í‘œ í‘œì‹œ
                st.subheader("ğŸ“‹ Model Performance Metrics")
                metrics_df = pd.DataFrame({model: st.session_state.metrics[model] for model in st.session_state.metrics})
                st.write(metrics_df)
                
                # ìµœì  ëª¨ë¸ ì„ íƒ
                if st.session_state.best_model:
                    st.success(f"Best Model (based on RMSE): {st.session_state.best_model}")
                
                # ëª¨ë¸ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸
                st.subheader("ğŸ” Model Interpretation & Insights")
                
                st.markdown(f"""
                ### Time Series Analysis Results
                
                1. **Data Characteristics**:
                   - The selected variable ({st.session_state.selected_target}) shows distinct daily and weekly patterns.
                   - As seen in the decomposition results, there is a seasonality with a {st.session_state.period}-hour period.
                
                2. **Model Performance Comparison**:
                   - The {st.session_state.best_model} model showed the best performance based on RMSE.
                   - Model characteristics:
                     - ARIMA: Statistical model utilizing autocorrelation in time series data
                     - Exponential Smoothing: Method giving higher weights to recent observations
                     - Prophet: Facebook's time series model considering trend, seasonality, and holiday effects
                     - LSTM: Deep learning-based time series prediction model using recurrent neural networks
                
                3. **Applicability**:
                   - This prediction model can be used to develop a Seoul air quality forecasting system.
                   - By predicting times when fine dust concentration is expected to be high, it can help protect citizens' health.
                """)
                
                # ì„ íƒí•œ ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„
                if st.session_state.best_model in st.session_state.forecasts:
                    st.subheader(f"ğŸ“ˆ Best Model ({st.session_state.best_model}) Detailed Analysis")
                    
                    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
                    best_forecast = st.session_state.forecasts[st.session_state.best_model]
                    
                    # ì”ì°¨ ë¶„ì„
                    residuals_fig = visualizer.plot_residuals(st.session_state.test, best_forecast)
                    st.pyplot(residuals_fig)
    else:
        st.info("Please upload data or get data from API to start analysis.")

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
