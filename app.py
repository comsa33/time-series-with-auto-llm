"""
ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì‹œê³„ì—´ ë¶„ì„ ë©”ì¸ Streamlit ì•±
"""
import os
import warnings
import traceback
from datetime import datetime, timedelta

import streamlit as st
import pandas as pd
import numpy as np

# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
from config.settings import app_config
from utils.data_reader import get_seoul_air_quality
from utils.data_processor import DataProcessor
from utils.visualizer import TimeSeriesVisualizer

# ëª¨ë¸ ëª¨ë“ˆ - ì§ì ‘ import í•˜ì§€ ì•Šê³  í•„ìš”í•  ë•Œ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
# from models.model_factory import ModelFactory

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=app_config.APP_TITLE,
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê°ì²´ ì´ˆê¸°í™”
data_processor = DataProcessor()
visualizer = TimeSeriesVisualizer()

# ëª¨ë¸ íŒ©í† ë¦¬ ë™ì  ë¡œë“œ
@st.cache_resource
def get_model_factory():
    """
    ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    í•„ìš”í•  ë•Œë§Œ importí•˜ì—¬ ì‹œì‘ ì‹œ pmdarima ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    try:
        from models.model_factory import ModelFactory
        return ModelFactory()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”: pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return None


# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
@st.cache_data
def load_data(file_path=None, start_date=None, end_date=None):
    """
    CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        if file_path and os.path.exists(file_path):
            df = pd.read_csv(file_path)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
            return df
        else:
            st.info("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            
            if not start_date or not end_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ í•œ ë‹¬
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            
            df = get_seoul_air_quality(app_config.SEOUL_API_KEY, start_date, end_date)
            
            if df is not None and not df.empty:
                # íŒŒì¼ë¡œ ì €ì¥
                os.makedirs(app_config.DATA_DIR, exist_ok=True)
                df.to_csv(app_config.DEFAULT_DATA_FILE, index=False, encoding='utf-8-sig')
                st.success(f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {app_config.DEFAULT_DATA_FILE}")
            
            return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ì•± í—¤ë” í•¨ìˆ˜
def render_header():
    """
    ì•± í—¤ë” ë Œë”ë§
    """
    st.title(app_config.APP_TITLE)
    st.markdown(app_config.APP_DESCRIPTION)
    
    # í™•ì¥ ê°€ëŠ¥í•œ ì•± ì†Œê°œ
    with st.expander("ğŸ“Œ ì•± ì†Œê°œ ë° ì‚¬ìš© ë°©ë²•"):
        st.markdown("""
        ### ì•± ì†Œê°œ
        ì´ ì•±ì€ ì„œìš¸ì‹œ IoT ë„ì‹œë°ì´í„° ì¤‘ ëŒ€ê¸°ì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œê³„ì—´ ë¶„ì„ ê¸°ë²•ì„ ë¹„êµí•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        ### ì£¼ìš” ê¸°ëŠ¥
        1. **ë°ì´í„° íƒìƒ‰**: ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ë°ì´í„° ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™”
        2. **ì‹œê³„ì—´ ë¶„í•´**: ì¶”ì„¸, ê³„ì ˆì„±, ë¶ˆê·œì¹™ì„± ë¶„í•´ ë° ë¶„ì„
        3. **ëª¨ë¸ ë¹„êµ**: ARIMA/SARIMA, ì§€ìˆ˜í‰í™œë²•, Prophet, LSTM ë“± ë‹¤ì–‘í•œ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ
        4. **ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€**: RMSE, MAE, R^2 ë“± ë‹¤ì–‘í•œ ì„±ëŠ¥ ì§€í‘œ ê¸°ë°˜ í‰ê°€
        
        ### ì‚¬ìš© ë°©ë²•
        1. ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘ ì˜µì…˜ ì„ íƒ
        2. ë¶„ì„í•  ì¸¡ì •ì†Œì™€ ë³€ìˆ˜(PM10, PM25 ë“±) ì„ íƒ
        3. ì‹œê³„ì—´ ë¶„ì„ ì˜µì…˜ ì„¤ì • ë° ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        4. ê²°ê³¼ íƒ­ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
        """)


# ë©”ì¸ í•¨ìˆ˜
def main():
    # ì•± í—¤ë” ë Œë”ë§
    render_header()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š ë¶„ì„ ì„¤ì •")
    
    # ë°ì´í„° ë¡œë“œ ë°©ì‹ ì„ íƒ
    data_source = st.sidebar.radio(
        "ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ",
        ["APIì—ì„œ ê°€ì ¸ì˜¤ê¸°", "íŒŒì¼ ì—…ë¡œë“œ"]
    )
    
    df = None
    
    if data_source == "APIì—ì„œ ê°€ì ¸ì˜¤ê¸°":
        st.sidebar.subheader("API ì„¤ì •")
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        today = datetime.now()
        default_end_date = today.strftime("%Y-%m-%d")
        default_start_date = (today - timedelta(days=30)).strftime("%Y-%m-%d")
        
        start_date = st.sidebar.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            datetime.strptime(default_start_date, "%Y-%m-%d")
        )
        
        end_date = st.sidebar.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            datetime.strptime(default_end_date, "%Y-%m-%d")
        )
        
        if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
            with st.spinner("ì„œìš¸ì‹œ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                df = load_data(
                    start_date=start_date.strftime("%Y-%m-%d"),
                    end_date=end_date.strftime("%Y-%m-%d")
                )
    else:
        st.sidebar.subheader("íŒŒì¼ ì—…ë¡œë“œ")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.sidebar.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
        
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            if 'MSRDT' in df.columns:
                df['MSRDT'] = pd.to_datetime(df['MSRDT'])
        else:
            # ê¸°ì¡´ íŒŒì¼ ì‚¬ìš©
            if os.path.exists(app_config.DEFAULT_DATA_FILE):
                use_existing = st.sidebar.checkbox("ê¸°ì¡´ ì €ì¥ëœ ë°ì´í„° ì‚¬ìš©", value=True)
                if use_existing:
                    df = load_data(file_path=app_config.DEFAULT_DATA_FILE)
            else:
                st.sidebar.warning("ì €ì¥ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
    
    # ë°ì´í„°ê°€ ë¡œë“œë˜ë©´ ë¶„ì„ ì‹œì‘
    if df is not None and not df.empty:
        analyze_data(df)
    else:
        st.info("ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ APIì—ì„œ ê°€ì ¸ì™€ì„œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")


def analyze_data(df):
    """
    ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
    """
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.write(df.head())
    
    # ê¸°ë³¸ ì •ë³´
    st.subheader("ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ë°ì´í„° í¬ê¸°:** {df.shape[0]} í–‰ Ã— {df.shape[1]} ì—´")
        st.write(f"**ê¸°ê°„:** {df['MSRDT'].min()} ~ {df['MSRDT'].max()}")
    
    with col2:
        if 'MSRSTE_NM' in df.columns:
            st.write(f"**ì¸¡ì •ì†Œ ìˆ˜:** {df['MSRSTE_NM'].nunique()}ê°œ")
            st.write(f"**ì¸¡ì •ì†Œ ëª©ë¡:** {', '.join(sorted(df['MSRSTE_NM'].unique()))}")
    
    # ì¸¡ì •ì†Œ ì„ íƒ
    st.sidebar.subheader("ğŸ” ë¶„ì„ ì˜µì…˜")
    
    if 'MSRSTE_NM' in df.columns:
        stations = ['ì „ì²´ í‰ê· '] + sorted(df['MSRSTE_NM'].unique().tolist())
        selected_station = st.sidebar.selectbox("ì¸¡ì •ì†Œ ì„ íƒ", stations)
        
        if selected_station == 'ì „ì²´ í‰ê· ':
            selected_station = None
    else:
        selected_station = None
        st.sidebar.info("ì¸¡ì •ì†Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
    numeric_columns = df.select_dtypes(include=np.number).columns.tolist()
    target_options = [col for col in numeric_columns if col in ['PM10', 'PM25', 'O3', 'NO2', 'CO', 'SO2']]
    
    if not target_options:
        target_options = numeric_columns
    
    if target_options:
        selected_target = st.sidebar.selectbox(
            "ë¶„ì„í•  ë³€ìˆ˜ ì„ íƒ", 
            target_options,
            index=0 if 'PM10' in target_options else 0
        )
    else:
        st.error("ë¶„ì„í•  ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    series = data_processor.preprocess_data(df, selected_target, selected_station)
    
    # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
    st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”")
    
    # ì„ íƒí•œ ì¸¡ì •ì†Œì™€ ë³€ìˆ˜ì— ëŒ€í•œ ì‹œê³„ì—´ ê·¸ë˜í”„
    station_text = f"{selected_station}ì˜ " if selected_station else "ì„œìš¸ì‹œ ì „ì²´ "
    fig = visualizer.plot_timeseries(
        series,
        title=f"{station_text}{selected_target} ì‹œê³„ì—´ ë°ì´í„°",
        ylabel=selected_target
    )
    st.pyplot(fig)
    
    # ì‹œê³„ì—´ ë¶„í•´
    st.subheader("ğŸ”„ ì‹œê³„ì—´ ë¶„í•´")
    
    # ê³„ì ˆì„± ì£¼ê¸° ì„ íƒ
    default_period = 24  # ê¸°ë³¸ê°’: 24ì‹œê°„(ì¼ë³„) ì£¼ê¸°
    min_period = 2
    max_period = min(len(series) // 2, 168)  # ìµœëŒ€ ì¼ì£¼ì¼(168ì‹œê°„) ë˜ëŠ” ë°ì´í„° ê¸¸ì´ì˜ ì ˆë°˜
    
    period = st.sidebar.slider(
        "ê³„ì ˆì„± ì£¼ê¸° (ì‹œê°„)",
        min_value=min_period,
        max_value=max_period,
        value=default_period
    )
    
    try:
        # ì‹œê³„ì—´ ë¶„í•´ ìˆ˜í–‰
        decomposition = data_processor.decompose_timeseries(series, period)
        
        # ë¶„í•´ ê²°ê³¼ ì‹œê°í™”
        decomp_fig = visualizer.plot_decomposition(decomposition)
        st.pyplot(decomp_fig)
        
        # ì •ìƒì„± ê²€ì •
        st.subheader("ğŸ” ì •ìƒì„± ê²€ì •")
        
        stationarity_result = data_processor.check_stationarity(series)
        
        # ì •ìƒì„± ê²€ì • ê²°ê³¼ í‘œì‹œ
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**ADF í†µê³„ëŸ‰:** {stationarity_result['test_statistic']:.4f}")
            st.write(f"**p-ê°’:** {stationarity_result['p_value']:.4f}")
            
            # ì •ìƒì„± ì—¬ë¶€
            if stationarity_result['is_stationary']:
                st.success("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±(Stationary)ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
            else:
                st.warning("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì •ìƒì„±(Stationary)ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        with col2:
            st.write("**ì„ê³„ê°’:**")
            for key, value in stationarity_result['critical_values'].items():
                st.write(f"{key}: {value:.4f}")
        
        # ACF, PACF ë¶„ì„
        st.subheader("ğŸ“Š ACF/PACF ë¶„ì„")
        
        acf_values, pacf_values = data_processor.get_acf_pacf(series)
        acf_pacf_fig = visualizer.plot_acf_pacf(acf_values, pacf_values)
        st.pyplot(acf_pacf_fig)
        
    except Exception as e:
        st.error(f"ì‹œê³„ì—´ ë¶„í•´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {traceback.format_exc()}")
    
    # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    st.subheader("ğŸ¤– ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡")
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    test_size = st.sidebar.slider(
        "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨",
        min_value=0.1,
        max_value=0.5,
        value=app_config.DEFAULT_TEST_SIZE,
        step=0.05
    )
    
    # ë¶„í•  ìˆ˜í–‰
    train, test = data_processor.train_test_split(series, test_size)
    
    # ëª¨ë¸ ì„ íƒ - ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ í•„ìš”í•  ë•Œë§Œ ë¡œë“œ
    model_factory = get_model_factory()
    
    if model_factory is None:
        st.error("ëª¨ë¸ íŒ©í† ë¦¬ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pmdarima í˜¸í™˜ì„± ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.error("ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        st.code("pip uninstall -y pmdarima numpy && pip install numpy==1.24.3 && pip install pmdarima==2.0.4")
        return
    
    available_models = model_factory.get_all_available_models()
    
    selected_models = st.sidebar.multiselect(
        "ë¶„ì„ ë°©ë²• ì„ íƒ",
        available_models,
        default=available_models[:2]  # ê¸°ë³¸ì ìœ¼ë¡œ ì²˜ìŒ ë‘ ëª¨ë¸ ì„ íƒ
    )
    
    # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ë²„íŠ¼
    if st.button("ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘"):
        if not selected_models:
            st.warning("ì ì–´ë„ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
            forecasts = {}
            metrics = {}
            
            # ëª¨ë¸ ê°œìˆ˜
            total_models = len(selected_models)
            completed_models = 0
            
            # ê° ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            for model_type in selected_models:
                status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                
                try:
                    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    model = model_factory.get_model(model_type)
                    
                    # ëª¨ë¸ë³„ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
                    if model_type == 'arima':
                        # ARIMA ëª¨ë¸ íŒŒë¼ë¯¸í„°
                        forecast, model_metrics = model.fit_predict_evaluate(
                            train, test,
                            seasonal=True,
                            m=period
                        )
                    elif model_type == 'exp_smoothing':
                        # ì§€ìˆ˜í‰í™œë²• ëª¨ë¸ íŒŒë¼ë¯¸í„°
                        forecast, model_metrics = model.fit_predict_evaluate(
                            train, test,
                            seasonal_periods=period
                        )
                    elif model_type == 'prophet':
                        # Prophet ëª¨ë¸ íŒŒë¼ë¯¸í„°
                        forecast, model_metrics = model.fit_predict_evaluate(
                            train, test,
                            daily_seasonality=True,
                            weekly_seasonality=True
                        )
                    elif model_type == 'lstm':
                        # LSTM ëª¨ë¸ íŒŒë¼ë¯¸í„°
                        forecast, model_metrics = model.fit_predict_evaluate(
                            train, test,
                            n_steps=min(48, len(train) // 10),  # ì‹œí€€ìŠ¤ ê¸¸ì´
                            lstm_units=[50, 50],
                            dropout_rate=0.2,
                            epochs=100,
                            batch_size=32,
                            validation_split=0.1
                        )
                    else:
                        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
                        forecast, model_metrics = model.fit_predict_evaluate(train, test)
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ ë° ë©”íŠ¸ë¦­ ì €ì¥
                    forecasts[model.name] = forecast
                    metrics[model.name] = model_metrics
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    completed_models += 1
                    progress_bar.progress(completed_models / total_models)
                    
                except Exception as e:
                    st.error(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            # ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ
            if forecasts:
                status_text.text("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                
                # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ")
                comparison_fig = visualizer.plot_forecast_comparison(train, test, forecasts)
                st.pyplot(comparison_fig)
                
                # ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”
                st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                metrics_fig = visualizer.plot_metrics_comparison(metrics)
                st.pyplot(metrics_fig)
                
                # ë©”íŠ¸ë¦­ í‘œ í‘œì‹œ
                st.subheader("ğŸ“‹ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                metrics_df = pd.DataFrame({model: metrics[model] for model in metrics})
                st.write(metrics_df)
                
                # ìµœì  ëª¨ë¸ ì„ íƒ
                rmse_values = {model: metrics[model]['RMSE'] for model in metrics}
                best_model = min(rmse_values.items(), key=lambda x: x[1])[0]
                st.success(f"RMSE ê¸°ì¤€ ìµœì  ëª¨ë¸: {best_model}")
                
                # ëª¨ë¸ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸
                st.subheader("ğŸ” ëª¨ë¸ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸")
                
                st.markdown(f"""
                ### ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ í•´ì„
                
                1. **ë°ì´í„° íŠ¹ì„±**:
                   - ì„ íƒí•œ ë³€ìˆ˜({selected_target})ëŠ” ëšœë ·í•œ ì¼ì¼ íŒ¨í„´ê³¼ ì£¼ê°„ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.
                   - ì‹œê³„ì—´ ë¶„í•´ ê²°ê³¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, {period}ì‹œê°„ ì£¼ê¸°ì˜ ê³„ì ˆì„±ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
                
                2. **ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ**:
                   - RMSE ê¸°ì¤€ìœ¼ë¡œ {best_model} ëª¨ë¸ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
                   - ê° ëª¨ë¸ë³„ íŠ¹ì„±:
                     - ARIMA: ì‹œê³„ì—´ ë°ì´í„°ì˜ ìê¸°ìƒê´€ì„±ì„ í™œìš©í•œ í†µê³„ì  ëª¨ë¸
                     - ì§€ìˆ˜í‰í™œë²•: ìµœê·¼ ê´€ì¸¡ì¹˜ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë°©ë²•
                     - Prophet: ì¶”ì„¸, ê³„ì ˆì„±, íœ´ì¼ íš¨ê³¼ë¥¼ ê³ ë ¤í•˜ëŠ” í˜ì´ìŠ¤ë¶ì˜ ì‹œê³„ì—´ ëª¨ë¸
                     - LSTM: ìˆœí™˜ì‹ ê²½ë§ì„ í™œìš©í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸
                
                3. **ì ìš© ê°€ëŠ¥ì„±**:
                   - ì´ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì„œìš¸ì‹œ ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ì‹œìŠ¤í…œì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                   - ë¯¸ì„¸ë¨¼ì§€ ë†ë„ê°€ ë†’ì•„ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì‹œê°„ëŒ€ë¥¼ ì‚¬ì „ì— ì•Œë¦¼ìœ¼ë¡œì¨, ì‹œë¯¼ë“¤ì˜ ê±´ê°•ì„ ë³´í˜¸í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                # ì„ íƒí•œ ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„
                if best_model in forecasts:
                    st.subheader(f"ğŸ“ˆ ìµœì  ëª¨ë¸ ({best_model}) ìƒì„¸ ë¶„ì„")
                    
                    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
                    best_forecast = forecasts[best_model]
                    
                    # ì”ì°¨ ë¶„ì„
                    residuals_fig = visualizer.plot_residuals(test, best_forecast)
                    st.pyplot(residuals_fig)


# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()
